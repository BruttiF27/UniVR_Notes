Lo scopo delle statistica inferenziale è, data una popolazione, di capire la sua vera distribuzione a partire dai dati che si possono osservare e studiare in un campione da essa estratto.\par
Sarà quindi necessario formulare un \textbf{modello statistico} di cui è nota la distribuzione ed i dati osservati, ma con i valori dei parametri incogniti. Ciò ridurrà il problema intero a questi due passaggi:
\begin{enumerate}
	\item Scegliere un valore plausibile per i valori dei parametri reali, quindi fare delle inferenze.
	\item Testare ipotesi sui valori per verificarne l'attendibilità.
\end{enumerate}
\noindent Le uniche inferenze statistiche di nostro interesse saranno quelle sulle \textbf{popolazioni normali} e di \textbf{Bernoulli}.

\section{Stima dei parametri}
Supponiamo che i dati siano realizzazioni di una variabile aleatoria $X$ con una  densità discreta o continua $f(x,\theta)$, dove $\theta$ è un parametro incognito. Dobbiamo stimarlo coi dati ottenuti dalle osservazioni su $X$; per farlo si usano due tipi di stima:
\begin{itemize}
	\item \textbf{Stima puntuale}; Dove si ottiene un singolo valore come stima per il valore di $\theta$.
	\item \textbf{Stima intervallare}; Si ottiene un intervallo di valori possibili per $\theta$, associando ad ogni intervallo un livello di fiducia che $\theta$ vi appartenga.
\end{itemize}
\noindent Partiamo dal primo tipo e dalle sue basi; per prima cosa sarà richiesto introdurre qualche concetto fondamentale. Anzitutto, chiamiamo \textbf{campione} di ampiezza $n$ una collezione di variabili aleatorie $X_n$ indipendenti e tutte con la stessa distribuzione $f(x;\theta)$, con $\theta$ parametro incognito.\par 
Una \textbf{Statistica} $T$ è invece una variabile aleatoria ottenuta come funzione del campione, ovvero $T = T(X_1, ..., X_n)$, ed uno \textbf{stimatore} è qualunque $T$ indipendente da $\theta$, è usata per stimarlo. Tendenzialmente, il ruolo è coperto dalla media campionaria per la varianza campionaria.\par 
Infine, chiamiamo \textbf{stima} il valore numerico assunto dallo stimatore sui dati osservati $x_1, ..., x_n$, ovvero, $\theta = T(x_1, ..., x_n)$.\newline

Sia ora $X_1, ..., X_n$ un campione casuale preso da una popolazione di densità $f(x,\theta)$, che dipende dal parametro $\theta$. Se interpretiamo \[f(x_1, ..., x_n; \theta)\]
\noindent come la verosimiglianza che si realizzi la n-upla $x_1, ..., x_n$ di dati quando $\theta$ è il vero valore del parametro, possiamo prendere come sua stima il \textit{valore che rende massima la funzione}, chiamato \textbf{stimatore di massima verosimiglianza}. Consigliato inoltre vederlo come logaritmo, in quanto ha uno stesso massimo e facilita i calcoli.
\begin{eg}
	% TODO
	INSERISCI ESEMPIO PER STIMATORE MAX VEROSIMIGLIANZA PER BERNOULLI E POPOLAZIONE NORMALE.
\end{eg}
\noindent Ma in che modo è possibile scegliere uno stimatore $T = T(X_1, ..., X_n)$? O meglio, come ne si valuta la \textbf{bontà}?\par 
Bisogna cercare di minimizzare la deviazione dal valore reale del parametro attraverso valore atteso e varianza. Non potendo tuttavia essere onniscenti, è inevitabile incappare in errori e per questo si introduce il concetto di \textbf{distorsione} o bias.
\begin{definition}
	\textbf{Bias}\par 
	\noindent Sia $T=T(X_1, ..., X_n)$ uno stimatore di $\theta$. Allora $b(T) = E(T)-\theta$ è detto bias di $T$ come stimatore di $\theta$. Se è nullo, T è detto stimatore corretto di $\theta$.
\end{definition}
\noindent Uno stimatore buono e utile controlla sia varianza che bias in modo contenuto, con lo scopo di fornire un risultato quanto più vicino alla realtà possibile senza essere troppo permissivo.
\begin{eg}
	% TODO
	INSERISCI ESEMPIO PER STIMATORE BUONO
\end{eg}
\noindent Inoltre, sia lo stesso stimatore $T=T(X_1, ..., X_n)$ del parametro $\theta$. Chiamiamo \textbf{errore quadratico medio} il valore atteso del quadrato della differenza fra lo stimatore ed il $\theta$. Si indica con:
\[MSE(T) = E[(T-\theta^2)^2] = Var(T) + b(T)^2\]
\noindent Se $T$ è corretto, allora questo errore quadratico medio sarà uguale alla varianza dello stimatore.\newline

\noindent Passiamo ora alla \textbf{stima intervallare}. Sia un campione estratto da una popolazione. Ci si aspetta che la stima ottenuta valutando lo stimatore sui dati osservati non sia l'effettivo valore di $\theta$, quindi è preferibile produrre un intervallo per il quale abbiamo una certa fiducia che il parametro vi appartenga. In tal merito, diamo le seguenti definizioni:
\begin{definition}
	\textbf{Stimatore intervallare}\par
	\noindent Sia $X_1, ..., X_n$ un campione casuale di una popolazione dove ci interessa stimare un parametro $\theta$. Siano poi $L_1 = L_1(X_1, ..., X_n)$, $L_2 = L_2(X_1, ..., X_n)$ due statistiche non dipendenti da $\theta$, tali che:
	\begin{center}
		$P(L_1 < \theta < L_2) = 1-\alpha$, con $\alpha \in (0,1)$
	\end{center}
	\noindent L'intervallo $(L_1, L_2)$ si dice \textbf{stimatore intervallare} del parametro $\theta$ e per costruirlo è necessario conoscere la distribuzione delle sue statistiche $L_1, L_2$.
\end{definition}
\begin{definition}
	\textbf{Intervallo di confidenza}\par
	\noindent Siano adesso $\hat{l}_1 = L_1(x_1,...,x_n)$ e $\hat{l}_2 = L_2(x_1, ..., x_n)$ i valori assunti dalle statistiche $L_1, L_2$ sui dati osservati $x_1, ..., x_n$.\par 
	Diremo quindi che $(\hat{l}_1, \hat{l}_2)$ è l'\textbf{intervallo di confidenza} di livello $1-\alpha$ per il parametro $\theta$.
\end{definition}
\noindent Notare che $(L_1, L_2)$ è un intervallo aleatorio che contiene il valore di $\theta$, mentre $(\hat{l}_1, \hat{l}_2)$ è una realizzazione del primo; data la sua natura non si presta ad alcuna valutazione probabilistica. Quindi, in sintesi:
\begin{enumerate}
	\item Otteniamo un \textit{campione casuale} $X_1, ..., X_n$ da una popolazione, il quale ci può far ottenere lo \textit{stimatore intervallare} $(L_1, L_2)$, composto da due variabili aleatorie, fra le quali è probabile accada il parametro $\theta$ di nostro interesse, quindi $P(L_1 < \theta < L_2) = 1-\alpha$, che risulta dare il \textit{coefficiente di fiducia}.
	\item Dal campione casuale effettuiamo delle inferenze, ottenendo il \textit{campione osservato} $x_1, ..., x_n$ che può avere solo valori numerici. Da questo possiamo ottenere l'\textit{intervallo di confidenza} $(\hat{l}_1, \hat{l}_2)$.
\end{enumerate}
\noindent Ultima cosa prima di passare ai vari casi di studio; per costruire lo stimatore intervallare è necessario conoscere la \textbf{distribuzione} delle statistiche $L_1, L_2$; quindi vediamo in che modo possono essere distribuite.\par 
Sia un campione estratto da una popolazione normale $X_1, ..., X_n$ e diciamo che ha una media $\mu \in \mathbb{R}$ e varianza $\sigma^2 > 0$. Siamo interessati a studiarne la distribuzione delle statistiche campionarie, ovvero la \textbf{media campionaria} $\overline{X}$ e la \textbf{varianza campionaria} $S^2$, per ottenere rispettivamente $\mu$ ed $\sigma^2$. Abbiamo che:
\begin{itemize}
	\item \textbf{Densità $\chi^2$ a $n-1$ gradi di libertà}\par 
	\noindent Le variabili aleatorie $\overline{X}$, $S^2$ sono indipendenti e per il teorema di limite centrale abbiamo che la media campionaria si distribuisce con una normale di media $\mu$ incognita e varianza $\frac{\sigma^2}{n}$, quindi: $\overline{X} \sim N(\mu, \frac{\sigma^2}{n})$. Inoltre:
	\[\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}\]
	\noindent La cui densità è asimmetrica e non nulla solo sui numeri reali positivi.
	\item \textbf{Densità $t$ di student a $n-1$ gradi di libertà}\par
	\noindent Si tratta di una densità con la forma a campana simmetrica rispetto ad $x=0$ e si stima con:
	\[\frac{\overline{X}-\mu}{\sqrt{\frac{S^2}{n}}}\sim t_{n-1}\]
\end{itemize}

%

\section{Intervalli di confidenza}
Passiamo adesso ai vari casi di studio che possiamo trovare nello svolgimento degli esercizi. Premetto che si somigliano tutti abbastanza e sarà utile capire come agire per poter capire anche la sezione seguente e prendere una decisione ponderata riguardo alle richieste.
\begin{itemize}
	\item \textbf{Intervalli di confidenza per la media di una popolazione normale, varianza nota}\par 
	\noindent Sia il campione $X_1, ..., X_n$, la media incognita $\mu \in \mathbb{R}$ e la varianza nota $\sigma^2 > 0$. Con $\alpha \in (0,1)$ dobbiamo ricavare intervalli di confidenza ad un livello $1-\alpha$ per la media $\mu$.\newline
	
	\noindent Diciamo che $\frac{\overline{X}-\mu}{\sqrt{\frac{\sigma^2}{n}}} = Z \sim N(0,1)$ e indichiamo con $z_{\alpha}$ il valore per cui $P(Z < z_{\alpha}) = \alpha$. Usando un pò di algebra noterai facilmente che:
	\[P(Z < z_{\alpha}) = \alpha \implies 1-P(Z>z_{\alpha}) = \alpha \implies 1-\alpha = P(Z < z_{\alpha})\]
	\noindent E che quindi ci servirà capire quell'area della funzione dove $Z < z_{\alpha}$. È probabile che venga richiesto l'intervallo totale (bilaterale) oppure una sola parte (unilaterale), quindi bisogna prendere la metà richiesta o tutto l'intervallo. Più in particolare, le due metà si ottengono con:
	\[1-\alpha = P(-z_{\alpha/2} < Z < z_{\alpha/2}) \implies 1-\alpha = \left(\overline{X}-z_{\alpha/2} \times \frac{\sigma}{\sqrt{n}} < \mu < \overline{X} + z_{\alpha/2}\times \frac{\sigma}{\sqrt{n}}\right)\]
	\noindent Dove il primo elemento della disequazione è $L_1$, il secondo è il parametro della media da stimare e l'ultimo è $L_2$. Sapendo ora di aver osservato dei dati $x_1, ..., x_n$ tali che $\overline{X}(x_1, ..., x_n) = \overline{x}$, abbiamo che ad un livello di confidenza $1-\alpha$, per la media $\mu$, gli intervalli ottenibili sono:
	\begin{itemize}
		\item \textbf{Bilaterale}: $(\overline{x} - z_{\alpha/2}\times \frac{\sigma}{\sqrt{n}}, \overline{x} + z_{\alpha/2}\times \frac{\sigma}{\sqrt{n}})$
		\item \textbf{Unilaterali}: $(\overline{x} - z_{\alpha}\times \frac{\sigma}{\sqrt{n}}, +\infty)$, $(-\infty, \overline{x}+z_{\alpha}\times \frac{\sigma}{\sqrt{n}})$
	\end{itemize}
	\noindent Per gli esercizi effettuare il seguente procedimento:
	\begin{enumerate}
		\item Calcola la media dei dati raccolti $\overline{x}$ e il livello di confidenza $\alpha$.
		\item Calcola il valore di $z_{\alpha}$ oppure $z_{\alpha/2}$.
		\item Prendi il risultato di $1-\alpha$ oppure $1-\frac{\alpha}{2}$ e trova il corrispondente valore nella tavola degli $\phi(x)$
		\item Hai tutto. Scrivi l'intervallo.
	\end{enumerate}
	\item \textbf{Intervalli di confidenza per la media di una popolazione normale, varianza incognita}\par 
	\noindent Sia il campione $X_1, ..., X_n$, la media $\mu \in \mathbb{R}$ e la varianza nota $\sigma^2 > 0$, ambo ignote. Con $\alpha \in (0,1)$ dobbiamo ricavare intervalli di confidenza ad un livello $1-\alpha$ per la media $\mu$.\newline
	
	\noindent Teniamo anzitutto a mente due cose:
	\begin{itemize}
		\item $\frac{\overline{X}-\mu}{{\frac{S}{\sqrt{n}}}} \sim t_{n-1}$, con $S$ deviazione standard campionaria.
		\item La densità $t$ di student ha una forma a campana simmetrica rispetto a $x=0$.
	\end{itemize}
	\noindent Se $X \sim t_n$, allora $t_{\alpha,n} \in \mathbb{R}$ è il valore per cui $P(X > t_{\alpha,n}) = \alpha$. Supponiamo nuovamente di avere dei dati $x_1, ..., x_n$ tali che $\overline{X}(x_1, ..., x_n) = \overline{x}$ ed $S(x_1, ..., x_n) = \hat{s}$.\par
	Allora a livello di confidenza $1-\alpha$ avremo i seguenti intervalli:
	\begin{itemize}
		\item \textbf{Bilaterale}: $(\overline{x}-t_{\alpha/2, n-1}\times \frac{\hat{s}}{\sqrt{n}}, \overline{x}+t_{\alpha/2, n-1}\times \frac{\hat{s}}{\sqrt{n}})$
		\item \textbf{Unilaterali}: $(\overline{x}-t_{\alpha, n-1}\times \frac{\hat{s}}{\sqrt{n}}, +\infty)$, $(-\infty, \overline{x}+t_{\alpha/2, n-1}\times \frac{\hat{s}}{\sqrt{n}})$
	\end{itemize}
	\noindent Per gli esercizi effettuare il seguente procedimento:
	\begin{enumerate}
		\item Calcola media $\overline{x}$ e deviazione standard $\hat{s}$.
		\item Calcola $\alpha$ e $t_{\alpha, n-1}$, con $n$ numero totale di elementi nel campione.
		\item Ottieni il valore di $t_{\alpha, n-1}$ dalla tavola dei valori di $t_n$.
		\item Scrivi l'intervallo.
	\end{enumerate}
	\item \textbf{Intervalli di confidenza per la varianza di una popolazione normale}\par
	\noindent Siano $X_1, ..., X_n$, $\mu$, $\sigma^2 > 0$, con media e varianza ignote. Possiamo creare degli intervalli di confidenza basandoci sul seguente fatto:
	\[\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1}\]
	\noindent Sia adesso $\alpha \in (0,1)$. Con $X \sim \chi^2_n$, allora $\chi^2_{\alpha,n} \in [0, +\infty)$ sarà il valore per cui $P(X > \chi^2_{\alpha,n}) = \alpha$.\par
	Con una semplice sostituzione abbiamo che l'intervallo di confidenza $1-\alpha$ è dato da: \[P\left(\chi^2_{1-\alpha/2, n-1} < \frac{(n-1)S^2}{\sigma^2} < \chi^2_{\alpha/2, n-1}\right) = P\left(\frac{(n-1)S^2}{\chi^2_{\alpha/2, n-1}} < \sigma^2 < \frac{(n-1)S^2}{\chi^2_{1-\alpha/2, n-1}} \right)\]
	\noindent Dunque avendo i dati $x_1, ..., x_n$ tali che $S^2(x_1, ..., x_n) = \hat{s}^2$, abbiamo che ad un livello di confidenza $1-\alpha$, per la varianza $\sigma^2$, gli intervalli ottenibili sono:
	\begin{itemize}
		\item \textbf{Bilaterale}: $\left(\frac{(n-1)\hat{s}^2}{\chi^2_{\alpha/2, n-1}}, \frac{(n-1)\hat{s}^2}{\chi^2_{1-\alpha/2, n-1}} \right)$
		\item \textbf{Unilaterali}: $\left(\frac{(n-1)\hat{s}^2}{\chi^2_{\alpha, n-1}} , +\infty\right)$, $\left(-\infty, \frac{(n-1)\hat{s}^2}{\chi^2_{1-\alpha, n-1}}\right)$
	\end{itemize}
	\noindent Per gli esercizi effetturare il seguente procedimento:
	\begin{enumerate}
		\item Calcolare $\hat{s}^2$ se non dato e poi $\alpha$ oppure $\frac{\alpha}{2}$.
		\item Calcolare $n-1$, poi ricercare il valore di $\chi^2_{\alpha, n-1}$ nella tabella.
		\item Scrivere l'intervallo ottenuto.
	\end{enumerate}
	\item \textbf{Intervalli di confidenza per la media di una popolazione di Bernoulli}\par 
	\noindent Qui abbiamo una popolazione di oggetti, ognuno dei quali, indipendentemente dagli altri, ha certi \textbf{requisiti} con una probabilità $q \in (0,1)$.\par 
	Se testiamo $n$ di questi oggetti, rilevando quanti di loro hanno tali requisiti, possiamo usare tale grandezza per ottenere un intervallo di confidenza per $q$.\par 
	Consideriamo $X$ come una variabile aleatoria binomiale di parametri $n,q$. Noi lavoreremo con casi semplici, altrimenti se $nq \geq 5$ e $nq(1-q) \geq 5$ si dice che il campione preso in considerazione è \textbf{numeroso}.\newline
	
	\noindent Poniamo lo stimatore di massima verosimiglianza di $q$: $Q = \frac{X}{n}$ e, sapendo di avere dati tali per cui $X = x \land Q(x) = \hat{q}$, usando il teorema del limite centrale si può ottenere un intervallo di confidenza bilaterale approssimato di livello $1-\alpha$ per $q$ come segue: \[\left(\hat{q} - z_{\alpha/2}\sqrt{\frac{\hat{q}(1-\hat{q})}{n}}, \hat{q} + z_{\alpha/2}\sqrt{\frac{\hat{q}(1-\hat{q})}{n}} \right)\]
	\noindent Questa scrittura è resa valida dal fatto che lo stimatore si approssima ad una distribuzione normale $N(q, \frac{q(1-q)}{n})$ e $z_{\alpha/2}$ è il quantile di ordine $\frac{\alpha}{2}$ di $Z \sim N(0,1)$.\newline
	
	\noindent Per gli esercizi effettuare il seguente procedimento:
	\begin{enumerate}
		\item Calcolare la percentuale di elementi coi requisiti adatti sul campione $\hat{q}$.
		\item Calcolare $z_{\alpha/2}$ ed $n$.
		\item Sostituisci i valori ottenuti alla formula dell'intervallo.
	\end{enumerate}
\end{itemize}

% TODO INSERISCI ESERCIZI PER OGNI CASO

%

\section{Verifica di ipotesi}
In questa sezione useremo quanto appena visto per decidere se i risultati ottenuti sono sufficientemente affidabili da rappresentare verità. Noi faremo quindi delle \textbf{ipotesi statistiche}, ovvero delle affermazioni su un parametro $\theta$ da cui dipende un campione $X_1, ..., X_n$. Matematicamente si tratta di un'asserzione di tipo: 
\begin{center}
	$\theta = \theta_0$, $\theta \leq \theta_0$, $\theta \leq \theta_0$
\end{center}
\noindent Con $\theta_0$ un certo valore del parametro. E possibile fare due tipi di ipotesi:
\begin{itemize}
	\item \textbf{Semplice}: Specifica un solo valore di $\theta$.
	\item \textbf{Composta}: Specifica un insieme di valori di $\theta$.
\end{itemize}
\noindent Il processo di verifica di un'ipotesi statistica è detto \textbf{test statistico}, dal quale avremo due alternative da cui scegliere, in base al nostro grado di confidenza; la \textbf{convinzione di partenza} $H_0$ e l'\textbf{affermazione contrapposta} $H_1$.\par 
È chiaro che ha senso fare testing solamente se si nutre qualche dubbio sulla veridicità di $H_0$ e vi è la possibilità che venga contraddetta. Tuttavia il test statistico non è la risposta assoluta all'affidabilità, bensì consente solo di vedere se i dati ottenuti sono compatibili o meno con $H_0$; la decisione finale sta al singolo, ed è ponderata da un certo grado di tolleranza di errore.\newline

\noindent Creiamo anzitutto uno stimatore di $\theta$, indicato con $ST = ST(X_1, ..., X_n)$. Per avere un test quantitativo è necessario creare la \textbf{regione critica} $C$, una soglia da non varcare per confermare la veridicità della convinzione iniziale. Segue le due regole:
\begin{itemize}
	\item Confermiamo $H_0$ se $st = ST(x_1, ..., x_n) \notin C$.
	\item Rifiutiamo $H_0$ se $st = ST(x_1, ..., x_n) \in C$.
\end{itemize}
\noindent Ma in che modo si costruisce la regione critica? Non è un valore fisso; bisogna prendere una decisione in base alla presenza di valori, troppo alti o troppo bassi, che fanno dubitare della veridicità di $H_0$. In tal merito, è possibile commettere due tipi di errore: rifiutare $H_0$ quando è vera si dice errore di \textbf{prima specie}, mentre accettarla quando è falsa si dice di \textbf{seconda specie}.\par
Per evitare di sbagliare si prendono in considerazione i due seguenti valori:
\begin{itemize}
	\item \textbf{Livello di significatività} $\alpha$: Un livello tale per cui la probabilità che $H_0$ sia nella regione critica è ad esso minore o uguale. In parole povere, dice la probabilità che si stia sbagliando a stimare. \[P_{H_0}(ST \in C) \leq \alpha\]
	\item \textbf{Valore-p dei dati}: Si tratta di un valore che indica il livello di significatività \textbf{critico}, ovvero il numero estremo superiore o estremo inferiore che non deve essere superato per far sì che valga $H_0$.
	\[ValP = sup\{\alpha:ST\notin C\} = inf\{\alpha:ST\in C\}\]
\end{itemize}
\noindent Fare attenzione ad usare queste restrizioni con cautela; è necessario prima osservare i dati del campione, per poi scegliere i relativi livelli di significatività.

\section{Testing su una popolazione}
\begin{itemize}
	\item \textbf{Test per la media di una popolazione normale con varianza nota}\par 
	\noindent Sia $X_1, ..., X_n$ campione estratto da una popolazione normale, con media $\mu \in \mathbb{R}$ ignota e varianza $\sigma^2 > 0$ nota. La dinamica decisionale è la seguente:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
		\hline
		$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
		\hline
		$\mu = \mu_0$ & $\mu \neq \mu_0$ & & $|st| > z_{\alpha/2}$\\
		$\mu \leq \mu_0$ & $\mu > \mu_0$ & $\dfrac{\overline{X}-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)$ & $st > z_{\alpha}$\\
		$\mu \geq \mu_0$ & $\mu < \mu_0$ & & $st < -z_{\alpha}$\\
		\hline
		\end{tabular}
	\end{table}
	\item \textbf{Test per la media di una popolazione normale con varianza ignota}\par 
	\noindent Sia $X_1, ..., X_n$ campione estratto da una popolazione normale, con media $\mu \in \mathbb{R}$ e varianza $\sigma^2 > 0$, ambo ignote. La dinamica decisionale è la seguente:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$\mu = \mu_0$ & $\mu \neq \mu_0$ & & $|st| > t_{\alpha/2,n-1}$\\
			$\mu \leq \mu_0$ & $\mu > \mu_0$ & $\dfrac{\overline{X}-\mu_0}{S/\sqrt{n}}\sim t_{n-1}$ & $st > t_{\alpha,n-1}$\\
			$\mu \geq \mu_0$ & $\mu < \mu_0$ & & $st < -t_{\alpha,n-1}$\\
			\hline
		\end{tabular}
	\end{table}
	\item \textbf{Test per la varianza di una popolazione normale}\par
	\noindent Sia $X_1, ..., X_n$ campione estratto da una popolazione normale, con media $\mu \in \mathbb{R}$ e varianza $\sigma^2 > 0$, ambo ignote. La dinamica decisionale è la seguente:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$\sigma^2 = \sigma^2_0$ & $\sigma^2 \neq \sigma^2_0$ & & $st < \chi^2_{1-\alpha/2, n-1} \lor st > \chi^2_{\alpha/2, n-1}$\\
			$\sigma^2 \leq \sigma^2_0$ & $\sigma^2 > \sigma^2_0$ & $\dfrac{(n-1)S^2}{\sigma^2_0} \sim \chi^2_{n-1}$ & $st > \chi^2_{\alpha, n-1}$\\
			$\sigma^2 \geq \sigma^2_0$ & $\sigma^2 < \sigma^2_0$ & & $st < \chi^2_{1-\alpha, n-1}$\\
			\hline
		\end{tabular}
	\end{table}
	\item \textbf{Test asintotici per la media di una popolazione di Bernoulli}\par 
	\noindent Qui useremo il teorema del limite centrale per costruire dei test asintotici per il parametro $q \in (0,1)$ di una popolazione di Bernoulli.\par
	Sia $X_1, ..., X_n$ un campione casuale estratto dalla suddetta popolazione con parametro incognito $q$. La dinamica decisionale è la seguente:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$q = q_0$ & $q \neq q_0$ &  & $|st| > z_{\alpha/2}$\\
			$q \leq q_0$ & $q > q_0$ & $\dfrac{Q-q_0}{\sqrt{\frac{q_0(1-q_0)}{n}}}\sim N(0,1)$ & $st > z_{\alpha}$\\
			$q \geq q_0$ & $q < q_0$ &  & $st < -z_{\alpha}$\\
			\hline
		\end{tabular}
	\end{table}
\end{itemize}

%

\section{Testing su due popolazioni}
Molto semplicemente, si tratta del concetto di testing appena visto, ma applicato a due popolazioni diverse. Dove è possibile ricercare ogni statistica campionaria, è di nostro interesse calcolare la sola media. Quindi le domande che dobbiamo porci sono: "Due approcci ad uno stesso problema hanno portato allo stesso risultato?", "A due popolazioni risulta la stessa media?".\par 
Seguono i vari casi di studio poco dissimili da quelli visti nelle sezioni precedenti:
\begin{itemize}
	\item \textbf{Confronto delle medie di due popolazioni normali, varianze note}\par 
	\noindent Siano $X_1, ..., X_n$ e $Y_1, ..., Y_m$ due campioni casuali indipendenti, provenienti da due popolazioni normali con medie $\mu_x, \mu_y \in \mathbb{R}$, ambo incognite, e varianze $\sigma_x^2 > 0$, $\sigma_y^2 > 0$, entrambe note. Seguono dinamiche decisionali:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$\mu_x = \mu_y$ & $\mu_x \neq \mu_y$ &  & $|st| > z_{\alpha/2}$\\
			$\mu_x \leq \mu_y$ & $\mu_x > \mu_y$ & $\dfrac{\overline{X}-\overline{Y}}{\sqrt{\frac{\sigma_x^2}{n}+\frac{\sigma_y^2}{n}}} \sim N(0,1)$ & $st > z_{\alpha}$\\
			$\mu_x \geq \mu_y$ & $\mu_x < \mu_y$ &  & $st -z_{\alpha}$\\
			\hline
		\end{tabular}
	\end{table}
	
	% TODO INSERISCI ESERCIZIO
	
	\item \textbf{Confronto delle medie di due popolazioni normali, varianze ignote uguali}\par 
	\noindent Siano $X_1, ..., X_n$, $Y_1, ..., Y_m$ due campioni casuali indipendenti provenienti da due popolazioni normali con medie $\mu_x, \mu_y \in \mathbb{R}$ e varianze $\sigma_x^2 > 0$, $\sigma_y^2 > 0$, tutte incognite.\par 
	Se il risultato della divisione fra le rispettive deviazioni campionarie applicate alle popolazioni, ovvero $\hat{s}_x^2/\hat{s}_y^2$, è compreso fra $\frac{1}{2}$ e $2$, possiamo assumere che le due varianze sono uguali. In tal caso, è possibile studiare la \textbf{varianza comune}, tramite la seguente formula: \[S_p^2 = \frac{(n-1)S_x^2 + (m-1)S_y^2}{n+m-2}\]
	\noindent Le dinamiche per l'ipotesi saranno poi le seguenti:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$\mu_x = \mu_y$ & $\mu_x \neq \mu_y$ & & $|st| > t_{\alpha/2, n+m-2}$\\
			$\mu_x \leq \mu_y$ & $\mu_x > \mu_y$ & $\dfrac{\overline{X}-\overline{Y}}{\sqrt{S_p^2(\frac{1}{n} + \frac{1}{m})}} \sim t_{n+m-2}$ & $st > t_{\alpha, n+m-2}$\\
			$\mu_x \geq \mu_y$ & $\mu_x < \mu_y$ & & $st < -t_{\alpha,n+m-2}$\\
			\hline
		\end{tabular}
	\end{table}
	
	% TODO AGGIUNGI ESERCIZIO
	
	\item \textbf{Confronto delle medie di due popolazioni normali, varianze incognite e diverse}\par 
	\noindent Siano $X_1, ..., X_n$, $Y_1, ..., Y_m$ due campioni casuali indipendenti provenienti da due popolazioni normali con medie $\mu_x, \mu_y \in \mathbb{R}$ e varianze $\sigma_x^2, \sigma_y^2 > 0$, tutte incognite.\par 
	Per lavorare su questo caso supponiamo di avere dei campioni numerosi $(n,m \geq 30)$; allora effettueremo dei test asintotici. Notare che nella formula per la statistica test, le $S_x^2, S_y^2$ sono le varianze campionarie del rispettivo campione. Le dinamiche per le ipotesi sono:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$\mu_x = \mu_y$ & $\mu_x \neq \mu_y$ & & $|st| > z_{\alpha/2}$\\
			$\mu_x \leq \mu_y$ & $\mu_x > \mu_y$ & $\dfrac{\overline{X}-\overline{Y}}{\sqrt{\frac{S_x^2}{n}\frac{S_y^2}{m}}} \sim N(0,1)$ & $st > z_{\alpha}$\\
			$\mu_x \geq \mu_y$ & $\mu_x < \mu_y$ & & $st < -z_{\alpha}$\\
			\hline
		\end{tabular}
	\end{table}
	
	% TODO AGGIUNGI ESERCIZIO
	
	\item \textbf{Confronto delle medie di due popolazioni normali, campioni accoppiati}\par 
	\noindent Adesso il campione preso in eaame consta di coppie di osservazioni, ciascuna relativa ad uno stesso individuo della popolazione, ovvero, ci saranno due osservazioni per ogni individuo del campione, rendendoli in pratica delle variabili aleatorie. Il dato di nostro interesse sarà la media fra i due dati.\par 
	Abbiamo quindi un campione casuale $(X_1, Y_1), ..., (X_n, Y_m)$, dove $X,Y$ sono normali, e bisogna costruire la differenza $W_i = X_i - Y_i$.\par 
	Otterremo quindi che $W_1, ..., W_i$ sarà il nostro campione di media $\mu_w = \mu_x - \mu_y \in \mathbb{R}$ e varianza $\sigma_w^2 > 0$, ambo incognite.\par 
	Bisognerà confrontare le due medie; per farlo eseguiremo un test-t sulla media $\mu_w$ con $\mu_0 = 0$.
	
	% TODO AGGIUNGI ESERCIZIO
	
	\item \textbf{Confronto asintotico delle medie di due popolazioni di Bernoulli}\par 
	\noindent Siano $X_1, ..., X_n$, $Y_1, ..., Y_m$ due campioni casuali indipendenti, provenienti da due popolazioni di Bernoulli con parametri $q_x, q_y \in (0,1)$, ambo incogniti. Per lavorare su questo caso sarà necessario uno \textbf{stimatore combinato}, dato dalla seguente formula: \[Q_p = \frac{nQ_x + mQ_y}{n+m}\]
	\noindent Dove $Q_x = \overline{X}$ è la proporzione di 1 nel primo campione e $Q_y = \overline{Y}$ nel secondo. Le dinamiche per le ipotesi sono:
	\begin{table}[h]
		\centering
		\begin{tabular}{|c|c|c|c|}
			\hline
			$H_0$ & $H_1$ & Statistica test ST & Rifiuto $H_0$ a livello $1-\alpha$ se\\
			\hline
			$q_x = q_y$ & $q_x \neq q_y$ & & $|st| > z_{\alpha/2}$\\
			$q_x \leq q_y$ & $q_x > q_y$ & $\dfrac{Q_x - Q_y}{\sqrt{Q_p(1-Q_p)(\frac{1}{n}+\frac{1}{m})}} \sim N(0,1)$ & $st > z_{\alpha}$\\
			$q_x \geq q_y$ & $q_x < q_y$ & & $st < -z_{\alpha}$\\
			\hline
		\end{tabular}
	\end{table}
	
	% TODO AGGIUNGI ESERCIZIO
	
\end{itemize}