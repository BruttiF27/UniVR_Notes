Il corso si propone di dare gli strumenti necessari alla comprensione della ricezione di segnali monodimensionali. Pone le basi per altre materie come elaborazione di segnali e immagini; richiede inoltre competenze di base ottenute da analisi 1 e 2, come anche nozioni di fisica 1. È consigliato iniziare questa materia solamente una volta dopo aver solidificato tali basi, specie riguardo i numeri complessi.

%

\section{Segnali e sistemi}
Partiamo dai concetti di base: \textbf{segnali} e \textbf{sistemi} sono due entità in stretta correlazione, e non possono esistere da sole. La prima riguarda le informazioni trasmesse nello spazio-tempo, mentre la seconda rappresenta lo strumento con il quale si andrà a elaborare la precedente.\par
Esistono due tipi di segnali di nostro interesse, quelli a \textbf{tempo continuo}, dati dai fenomeni fisici, e quelli a \textbf{tempo discreto}, in una forma approssimata per essere elaborati dalla macchina. Risulta finito nel tempo e nei valori.\newline

\noindent Come già visto nel corso di Architetture degli Elaboratori, viene seguito il seguente algoritmo per la conversione dei dati e la loro conseguente elaborazione:
\begin{enumerate}
	\item \textbf{Campionamento}: Divide in intervalli uguali il segnale ricevuto, qunidi passa da continuo a discreto. Non è un processo distruttivo.
	\item \textbf{Quantizzazione}: Approssima gli intervalli ottenuti ad un valore leggibile dalla macchina in base alla sua risoluzione. Da qui il segnale non è più revertibile.
	\item \textbf{Encoding}: Trasforma il segnale quantizzato in dati. Non sarà approfondito.
\end{enumerate}
\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{Images/RicezioneSegnale.png}
	\caption{Algoritmi di ricezione segnali}
	\label{fig:RicSgl}
\end{figure}
In questa parte di corso ci concentreremo su segnali unidimensionali non negativi, ovvero rappresentabili tramite funzioni lineari. In successione verranno approfonditi anche i segnali bidimensionali, usati per la rappresentazione di immagini, e tridimensionali, ovvero le stesse con colori.\par
Parliamo adesso dei \textbf{sistemi}. Questi detengono un'entrata ed un'uscita, anche se spesso viene usato un ulteriore \textbf{blocco di retroazione} per ricalibrare o modificare il segnale di output. In tal caso, l'uscita del blocco diventerà la nuova entrata del sistema principale. Un esempio di questo comportamento è il termostato. Di base segnala puramente la temperatura attuale, ma se attivato in automatico, cercherà di bilanciare la suddetta accendendo l'aria condizionata o i termoarredi.\newline

\noindent Passiamo ora alle notazioni utilizzate nel corso. I segnali si indicano con la lettera minuscola $f$, mentre le maiuscole sono usate per le \textbf{Trasformate}, le quali hanno il compito di convertire i segnali. Vedremo più tardi in dettaglio la loro utilità.\par
Le notazioni per variabili a tempo continuo sono $t, \tau, t_i$, mentre per quelle a tempo discreto si usa $k$. La scrittura $f(t)$ indica un segnale a tempo continuo. Per cogliere un istante specifico, si scrive $f(3)$, che ritornerà il valore di $f$ al tempo $3$.\par
I sistemi sono invece rappresentati come una scatoletta nera, con un'entrata $u(t)$ ed un'uscita $v(t)$. Per loro si usano lettere greche o maiuscole, come $\Sigma$. Generalmente lavoreremo con sistemi LTI, ovvero \textbf{Lineari Tempo Invariante}, ciò significa che vale la sovrapposizione degli effetti (lineare), e che a prescindere dal punto di ingresso del segnale nel sistema, l'uscita sarà sempre la stessa (tempo invariante).\newline

\noindent Il compito che ci poniamo è l'analisi dei sistemi tramite un approccio classico. Partiamo dal segnale, un qualunque evento fisico, e prendiamo per esempio una molla con una massa attaccata ad una sua estremità. Il movimento che questa effettua fino al ritornare stabile è il nostro segnale. Detto ciò, l'analisi è un processo diviso in quattro fasi:
\begin{enumerate}
	\item \textbf{Definizione del modello}: Per la rappresentazione del sistema verranno utilizzati grafici appositi, mentre per segnali a tempo continuo e discreto si useranno equazioni differenziali ed equazioni alle differenze rispettivamente.\par
	Essendo le equazioni differenziali algoritmicamente complesse, più avanti nel corso saranno introdotte le trasformate, che consentono di trasformare equazioni differenziali in equazioni di secondo grado con numeri complessi. In particolare:
	\begin{itemize}
		\item \textbf{Trasformata di Laplace}: Più generale, per segnali a tempo continuo.
		\item \textbf{Trasformata di Fourier}: Sottocategoria della precedente, usata sempre per segnali a tempo continuo.
		\item \textbf{Trasformata Zeta}: Per segnali a tempo discreto.
	\end{itemize}
	\item \textbf{Analisi di proprietà e stabilità}: La definizione del modello introduce proprietà ad esso associate. Per esempio, supponiamo che un'auto sia il nostro sistema; il freno, che riduce la sua accelerazione per poi fermare del tutto il veicolo, è una proprietà. Se questa agisce come inteso, il sistema è detto \textbf{stabile}.
	\item \textbf{Controllo delle proprietà}: Qui si parla di prestazioni, ovvero il costo utilizzato per produrre l'output richiesto. Chiaro che meno costa, meglio è.
	\item \textbf{Sintesi del modello}: Non vista nel corso, è utile per la correzione del sistema affinché risulti stabile.
\end{enumerate}
\noindent Sebbene siano il nostro principale campo di prova, nella realtà non esistono sistemi lineari. infatti noi prenderemo una parte del segnale il cui comportamento risulta simile ad una funzione lineare, effettuando, in parole povere, un'astrazione del segnale preso in esame.\newline

\noindent Approfondiamo ora la stabilità. Generalmente, quando la grandezza di un output non tende ad infinito, è detta stabile, ma ne abbiamo due tipi:
\begin{itemize}
	% TODO INSERISCI IMMAGINE
	\item \textbf{Stabilità BIBO}: L'acronimo sta per bounded input, bounded output. Afferma che se ho un input limitato in ampiezza, mi aspetto che lo sarà anche l'uscita. Formalmente: 
	\begin{center}
		$\exists M > 0.|u(t)| <  M \forall t \in \mathbb{R} \implies \exists N > 0.|v(t)| < N \forall t \in \mathbb{R}$
	\end{center}
	% TODO INSERISCI IMMAGINE
	\item \textbf{Stabilità asintotica}: Afferma che esiste un limite tale per cui il mio valore si annulla. Ciò vale sia in input che output. Quindi se cessa l'input, così farà l'output. Questa stabilità implica la precedente, ma non viceversa.
	\begin{center}
		$\forall t$ di $v(t).t\in \mathbb{R}$, $lim_{t_1 \to \infty} v(t) = 0$
	\end{center}
\end{itemize}
\noindent Abbiamo detto prima che i segnali sono rappresentati mediante equazioni differenziali; infatti il modello generale è dato da una doppia sommatoria con due indici diversi di un coefficiente, moltiplicata per una parte esponenziale ed una parte polinomiale.
\begin{definition}
	\textbf{Formula generale per la rappresentazione dei segnali}
	\begin{center}
		$y(t) = \sum_{i}\sum_{j} c_{ij} e^{\alpha t} \frac{t^e}{e!}$
	\end{center}
	\noindent In questa formula, $t$ è la variabile del tempo ed $\alpha$ è un numero complesso. Quest'ultimo è rappresentabile anche come $\lambda + \omega t$ e quindi scomponibile in due esponenziali. È ovviamente consentito passare in coordinate polari:
	\begin{itemize}
		\item $e^{j\omega} = cos(\omega t) + jsin(\omega t)$.
		\item $e^{\alpha t} = \rho(cos(\omega t) + jsin(\omega t))$.
	\end{itemize}
\end{definition}

%

\section{Tipi di segnali}
È stato precedentemente menzionato come i due tipi di segnali principali siano quelli a tempo continuo e discreto, è ora di associare il concetto ad effettive funzioni sulle quali andremo a lavorare.\newline

\noindent\textbf{Segnali sinusoidali}: $x(t) = Acos(\omega_o t + \phi)$; $x[n] = Acos(\Omega_0n + \phi)$\par
\noindent Le due formule sono usate per l'espressione dei segnali in forma sinusoidale, la prima a tempo continuo, la seconda a tempo discreto. Le componenti sono:
\begin{itemize}
	\item $A$: Ampiezza, indica l'altezza dell'onda in base all'asse delle y.
	\item $\omega_0$; $\Omega_0$: Frequenza, determinata dalla dilatazione delle singole onde. Si ottiene con $f = \frac{1}{t}$, dove $t$ è il periodo.
	\item $\phi$: Fase, punto di inizio del segnale.
\end{itemize}
\noindent Il punto d'intersezione con l'asse delle $y$ è dato da $Acos(\phi)$, detto \textbf{Shift temporale}, mentre il \textbf{Periodo} $t_0 = \frac{2\pi}{\omega_0}$ è la distanza fra le due ampiezze massime delle singole onde. Questo tipo di segnale detiene inoltre proprietà legate al tipo di funzione:
\begin{itemize}
	\item \textbf{Periodicità}: Esiste un certo periodo $t_0$ che se sommato a $t$ ritorna lo stesso risultato. $t_0$ è il numero più piccolo per il quale vale questa proprietà. Per il tempo discreto, non è garantita periodicità in quanto con l'approssimazione si potrebbe arrivare ad una perdita di dati.
	\item \textbf{Time shifting}: Una traslazione temporale, ovvero spostarsi avanti o indietro nel tempo rispetto al segnale, equivale ad un cambio di fase. Dove questa proprietà è sempre vera in segnali a tempo continuo, in quelli a tempo discreto potrebbe non valere.
	\item \textbf{Parità}: Data una fase $\phi = 0$, otterremo una funzione coseno, quindi pari. Vale $x(t) = x(-t)$.
	\item \textbf{Disparità}: Data una fase $\phi = -\frac{\pi}{2}$, otterremo una funzione seno, quindi dispari. Vale $x(t) = -x(-t)$.
\end{itemize}

% TODO INSERISCI IMMAGINE PER ENTRAMBI I TIPI DI SEGNALI

\noindent \textbf{Segnali esponenziali reali}: $x(t) = Ce^{at}; x[n] = Ce^{bn}$\par
\noindent Segnali che seguono le regole delle funzioni esponenziali, quindi cresce o decresce in base al segno dell'esponente. Nelle rispettive formule, abbiamo poi: $C, a, b \in \mathbb{R}$.\par
In caso di time shift, la variabile modificata è $t$ o $n$, per la rispettiva formula, e ne influenza la scala. Si scriverà infatti: $Ce^{a(t+t_0)}$.\newline

% TODO Inserisci il disegno del segnale

\noindent Per quanto riguarda i segnali discreti, si preferisce passare ad una formula contratta, dove $\alpha=e^b$: \[x[n] = Ce^{bn} \equiv C(e^b \times e^n) \equiv C\alpha^n\]
\noindent Abbiamo quattro modi diversi per la loro rappresentazione in base al valore di $\alpha$ e al suo modulo:
\begin{itemize}
	\item $\alpha > 0$, $|\alpha| > 1$: cresce e tende ad infinito nel primo quadrante.
	\item $\alpha > 0$, $|\alpha| < 1$: Decresce e tende a 0 nel primo quadrante.
	\item $\alpha < 0$, $|\alpha| > 1$: Ha un comportamento oscillatorio, cresce e tende ad infinito nell'asse delle $x$.
	\item $\alpha < 0$, $|\alpha| < 1$: Ha un comportamento oscillatorio, decresce e tende a $0$ nell'asse delle $x$.
\end{itemize}

% TODO Inserisci il disegno del segnale

\noindent \textbf{Segnali esponenziali complessi}: $x(t) = ce^{at}; x[n] = c\alpha^n$\par
\noindent I segnali esponenziali complessi hanno un comportamento oscillatorio, il quale cresce o decresce verso l'asse delle $x$ in base al segno delle variabili $r$ e $|\alpha|$ nelle rispettive formule. Si dice che ha una forma sinusoidale smorzata. Nello specifico, infatti, per il tempo continuo si ha:
\begin{itemize}
	\item $c = |c|e^{j\theta}$, con forma polare.
	\item $a = r+j\omega_0$, con forma cartesiana.
\end{itemize}
\noindent Che ci fa ottenere, grazie alla formula di Eulero che consente di passare da esponenziale a forma polare del complesso: $e^{j(\omega_0t+\theta)} = cos(\omega_0t+\phi) + jsin(\omega_0t+\phi)$, quanto segue:
\begin{equation}
	\begin{split}
		x(t) &= |c|e^{j\theta}e^{(r+j\omega_0)t}\\
		&= |c|e^{rt}e^{j(\omega_0t+\theta)}\\
		&= |c|e^{rt}cos(\omega_0t+\phi) + jsin(\omega_0t+\phi)
	\end{split}
\end{equation}
\noindent Da questa equazione estesa è possibile differenziare i modi in cui si può scrivere graficamente il segnale; se $r > 0$, la sinusoide crescerà all'infinito, altrimenti decrescerà fino a $0$.

% TODO Inserisci grafici exp complessi continui

\noindent Per quanto riguarda invece il tempo discreto, le componenti sono:
\begin{itemize}
	\item $c = |c|e^{j\theta}$
	\item $\alpha = |\alpha|e^{j\Omega_0}$
\end{itemize}
\noindent Sostituiamole alla formula contratta per ottenere quella estesa, come prima:
\begin{equation}
	\begin{split}
		x[n] &= |c|e^{j\theta}(|\alpha|e^{j\Omega_0})^n\\
		&= |c||\alpha|^ne^{j(\Omega_0n\theta)}\\
		&= |c||\alpha|^ncos(\Omega_0n+\theta)+jsin(\Omega_0n+\theta)
	\end{split}
\end{equation}
\noindent Il grafico qui dipende dal valore di $|\alpha|$. Se maggiore di $0$, la sinusoide crescerà all'infinito verso l'asse delle $x$, altrimenti qui tenderà a $0$.

% TODO Inserisci grafici exp complessi discreti

%

\section{Distribuzioni}
Talvolta ci sono delle grandezze non misurabili numericamente e quando ciò ha luogo, ci serviamo dei segnali generalizzati. La loro particolarità riguarda essere definiti all'interno di un'operazione di integrale, il cui risultato ritornerà il valore cercato. Formalmente scriviamo l'\textbf{impulso di Dirac}: \[\int_{-\infty}^{+\infty} \sigma(t)\phi(t)dt = N\]
\noindent Dove $\sigma$ è la grandezza, $\phi$ lo strumento ed $N$ la misura.\par
Lo strumento di lavoro base per questa misurazione è invece detto \textbf{impulso unitario}, ed è una funzione che comprende un \textbf{supporto}, quindi la larghezza della funzione, infinitesimo, \textbf{altezza} infinita, ed un'\textbf{area}, quindi l'integrale, uguale ad $1$. Inoltre, è definita in $[0^-, 0^+]$ e si denota con: \[\int_{-\infty}^{+\infty} \delta(t) dt = 1\]
\noindent Chiariamo che la grandezza da misurare è $\delta t$, lo strumento è la costante $1$ moltiplicata per la grandezza, ed $1$ è il risultato. In natura questa funzione non esiste, ma è utile per effettuare approssimazioni e quindi anche il \textbf{campionamento}. I casi ricorsivi sono: \begin{center}
	$\delta(t) = \begin{cases}
		\infty\implies 0\\
		0
	\end{cases}$
\end{center}
\noindent 








\begin{comment}


Due funzioni non derivabili, ma fondamentali per l'analisi dei segnali
- Finestra rettangolare unitaria
Rettangolo di altezza 1. Definita fra -t/2 e t/2. Definita come:
\pi(t) = \begin{cases}
	1 in -t/2 \leq t \leq t/2\\
	0 altrimenti
\end{cases}
Quest'onda se ripetuta nel tempo otteniamo un'onda quadra. Utile per il controllo dei motori, per esempio.

- finestra triangolare unitaria/impulso triangolare unitario
Triangolo di altezza 1. Definita come \Lambda(t) = \begin{cases}
	1-|t| in -T \leq t \leq T\\
	0 altrimenti
\end{cases}
Non viene usata per fare controlli particolari, ma funziona per fare filtraggi migliori. Se ripetuta nel tempo abbiamo un'onda triangolare. Ci aiuterà a generare le sinusoidi

Abbiamo parlato di funzioni unitarie, quindi di ampiezza 1. Per considerare il caso generale, sostituire il valore dell'ampiezza all'1 nella definizione.

Come ottenere l'impulso?
Lo definiamo come una serie di funzioni fra cui cambiamo dei valori.
Il risultato dell'area deve SEMPRE essere 1.
Per il quadrato, base*altezza
Per il triangolo, base*altezza*1/2

Tuttavia, per entrambe vale: \delta(t) = lim_{n\to\infty} Area_n = 1.

Il triangolo ci riesce a definire qual è la derivata dell'impulso (useremo un trucco per farlo, altrimenti è un casino). Si tratta di un impulso che cresce e che decresce, nell'infinitesimo molto vicino a 0.
A noi più che questo interessa l'integrale di un impulso.

Questo introduce una serie di funzioni dette polinomiali o segnali canonici.
Questi segnali sono definiti come l'integrale dell'impulso o l'integrale dell'integrale dell'... dell'impulso.
\delta_{-n}(t) = \begin{cases}
	\frac{t^{n-1}}{(n-1)!} t\geq 0\\
	0 altrimenti
\end{cases}

Integrando un impulso otteniamo la funzione gradino: \delta_{-1}(t) = \begin{cases}
	\frac{t^{1-1}}{(1-1)!} t\geq 0\\
	0 altrimenti
\end{cases} = \begin{cases}
	1 t\geq 0\\
	0 altrimenti
\end{cases}
Questa funzione permette di garantire la causalità.
f(t)*\delta_{-1}(t) = f_1(t), che è causale.

What about integrale di integrale? (poco usata) Otteniamo la funzione rampa:
\delta_{-2}(t) = \begin{cases}
	\frac{t^{2-1}}{2-1} t\geq 0\\
	0 altrimenti
\end{cases} = \begin{cases}
	t t\geq 0\\
	0 altrimenti
\end{cases}

What about integrale di integrale di integrale? È una parabola, hai già capito. Basta.

-- A che servono i segnali polinomiali?
A caratterizzare il sistema. Per farlo si cerca di dargli un input (tendenzialmente una funzione gradino) e vediamo il tempo usato per ritornare il valore. Ciò è utile per avere una misura standard nel testing dei sistemi.

- proprietà dell'impulso
Segnale ideale, centrato in 0, definito fra 0^- e 0^+ con altezza 1.
È una funzione pari.
Ha sempre area unitaria.
Proprietà del campionamento o riproducibilità del segnale (Importante): Se abbiamo una funzione continua in t_0 v:R\to R, allora v(t)\delta(t-t_o) = v(t_0)\delta(t-t_0), per t \in R.
Fondamentalmente significa che se prendo un impulso traslato nel tempo t_0 e lo moltiplico per una funzione, ottengo il valore della funzione in quel punto t_0.
Quindi per passare da continuo a discreto si moltiplica la funzione con l'impulso.

La formula può essere anche riscritta come \[N(t_0) = \int_{-\infty}^{+\infty} v(\tau)\delta(\tau-t_0) d\tau\]
Quindi il valore di una funzione in t_0 è l'integrale della funzione moltiplicata per un impulso traslato in t_0.

\end{comment}