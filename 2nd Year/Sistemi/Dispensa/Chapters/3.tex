\section{Risposta in frequenza}
Per risposta in frequenza intendiamo l'output di un sistema quando in ingresso è fornita una funzione sinusoidale. Per lo studio degli input non utilizzeremo questa forma, bensì una di esponenziale complessa, che chiameremo \textbf{fasore}, e rappresenta un vettore roteante in una circonferenza unitaria, quindi di raggio $1$. Si rappresentano con: \[u(t) = Ae^{j(\omega_0 t + \phi)} \equiv Ae^{j\omega_0 t}e^{j\phi}\]
\noindent Mentre la risposta ha una forma simile a quella forzata, già vista nel capitolo precedente. La differenza di fondo è la presenza del fasore nell'equazione, il quale assume il ruolo di input $u(t)$ e consente di differenziare le varie frequenze nell'istante di tempo richiesto. Si scrive:
\begin{equation}
	\begin{split}
		v(t) &= \int_{-\infty}^{+\infty} h(\tau) u(t-\tau) d\tau\\
			&= \int_{-\infty}^{+\infty} h(\tau) Ae^{j[\omega_0(t-\tau)+\phi]} d\tau\\
			&= Ae^{j(\omega_0 t+\phi)} \int_{-\infty}^{+\infty} h(t)e^{-j\omega_0\tau} d\tau
	\end{split}
\end{equation}
\noindent Abbiamo potuto rimuovere le costanti dall'integrale, lasciando al suo interno quella che effettivamente chiamiamo risposta in frequenza $H(j\omega)$, rappresentata dall'integrazione della risposta impulsiva con il fasore. Quindi, l'output è descritto come: \[v(t) = H(j\omega_0)Ae^{j(\omega_0 t + \phi)}\]
\noindent Una caratteristica importante da ricordare è che se il modulo di questo output è minore di infinito, allora il sistema converge ed è sicuramente almeno BIBO-stabile.\par
Finora abbiamo svolto i calcoli facendoci del male con le equazioni differenziali, quindi in questo capitolo verranno introdotte le \textbf{trasformate}, il cui scopo è cercare di semplificarci lo svolgimento e la comprensione degli esercizi. Vedremo infatti che la risposta in frequenza risulta essere la \textbf{Trasformata di Fourier} della risposta impulsiva di un sistema e quindi anche la \textbf{Trasformata di laplace} della risposta impulsiva ristretta all'asse immaginario. Queste due considerazioni sono equivalenti e si indicano con:
\[H(j\omega) = \mathcal{F}[h(t)](s) = \mathcal{L}[h(t)](s); s=j\omega\]
\noindent Le trasformate sono utili per saltare passaggi laboriosi di analisi 2; con Laplace, trasformeremo equazioni differenziali in algebriche con dominio complesso. Vedremo infatti che $s$ è una variabile complessa.\par
Tuttavia, per riportare un risultato equivalente a quello che avremmo ottenuto senza l'ausilio della trasformata, sarà necessario attuare una trasformata inversa, o \textbf{antitrasformata}, ed infine ottenere la soluzione nel dominio del tempo.

%

\section{Trasformata di Laplace unilatera}
Sia $v(t)$ una funzione generica con $t\in\mathbb{R}$, ottenuta come somma di funzioni reali a variabile reale o complessa. Per far sì che accetti la trasformata di Laplace, deve rispettare i seguenti criteri:
\begin{itemize}
	\item Funzione localmente sommabile nell'intervallo $[0, \infty)$. Quindi che: \[\int_a^b |v(t)| dt < \infty, \forall a,b \in [0,\infty)\]
	\item Funzione formata da un insieme finito di segnali polinomiali.
\end{itemize}
\noindent Noi definiamo la \textbf{Trasformata di Laplace}, o TdL unilatera come l'integrale della moltiplicazione fra l'output ed il fasore. Si tratta di una funzione che ha sia dominio che codominio in campo complesso e si scrive: \[V(s) = \int_{0^-}^{+\infty} v(t)e^{-st} dt \equiv L[v(t)](s)\]
\noindent Notare che la convenzione di scrittura vede le funzioni trasformate con la lettera maiuscola. Da qui in avanti le funzioni verranno così distinte. Questa formula è fondamentale perché rappresenta la base di ogni trasformata che andremo ad utilizzare. Sebbene esistano tabelle apposite per utilizzarle out of the pocket, in mancanza di esse si dovrebbe partire da qua. Inoltre, attenzione: con una funzione $v(t)$ generica localmente sommabile, non abbiamo la certezza che lo sia anche la sua trasformata; ragion per cui è necessario definire la \textbf{regione di convergenza} di quest'ultima.\par
Definiamo questa regione $RdC$ come un semipiano positivo, posto alla destra di un determinato asse $\alpha$, considerato come ascissa di convergenza. Scriviamo: \[RdC = \{s\in C | Re(s) > \alpha\}\]
\begin{dimostrazione}
	\textbf{RdC è un semipiano positivo}\par
	\noindent Sia $v(t)$ una combinazione lineare di esponenziali, vogliamo dimostrare che la regione di convergenza della sua trasformata è un semipiano positivo definito come appena visto. Abbiamo quindi:
	\begin{itemize}
		\item $v(t) = \sum_{i=0}^n c_ie^{\lambda it}; \lambda_i = \sigma_i+j\omega_i \in \mathbb{C}$
		\item $RdC = \{s\in C | Re(s) > \alpha\}$
		\item $\mathcal{L}[v(t)](s) = \int_{0^-}^{+\infty} v(t)e^{-st}$
	\end{itemize}
	\noindent Per prima cosa, partiamo dalla definizione di trasformata e sostituiamo a $v(t)$ la nostra supposizione, ovvero che sia combinazione lineare. Otteniamo:
	\begin{equation}
		\begin{split}
			V(t) &= \int_{0^-}^{+\infty} \sum_{i=0}^n c_ie^{\lambda it}e^{-st} dt\\
			&= \sum_{i=0}^n c_i \int_{0^-}^{+\infty} e^{\lambda it}e^{-st} dt
		\end{split}
	\end{equation}
	\noindent Prendendo un generico $i$ possiamo porre le definizioni di numero complesso per $\lambda_i$ ed $s$, dandoci: \[\lambda_i = \sigma_i + j\omega_i; s=\sigma + j\omega\]
	\noindent Ciò ci consente di riscrivere l'integrale come segue:
	\begin{equation}
		\begin{split}
			\int_{0^-}^{+\infty} e^{\sigma_i t}e^{j\omega_i t}e^{-\sigma t}e^{-j\omega t} dt &= \int_{0^-}^{+\infty} e^{(\sigma_i-\sigma + j\omega_i -j\omega)t} dt\\
			&= \left[\left(\frac{e^{(\sigma_i-\sigma + j\omega_i -j\omega)t}}{\sigma_i-\sigma + j\omega_i -j\omega}\right)\right]_{0^-}^{+\infty}\\
			&= \lim_{t\to\infty}\left(\frac{e^{(\sigma_i-\sigma)t}e^{j(\omega_i-\omega)t}}{\sigma_i-\sigma + j\omega_i -j\omega}\right) - \frac{1}{\sigma_i-\sigma + j\omega_i -j\omega}
		\end{split}
	\end{equation}
	\noindent Possiamo notare che $e^{j(\omega_i-\omega)t}$ è un fasore, quindi necessariamente uguale ad $1$, possiamo quindi rimuoverlo. La vera parte che ci interessa è $e^{(\sigma_i-\sigma)t}$, perché saprà dirci se l'integrale converge, perché lo farà se $\sigma_i < \sigma$.\par
	$\sigma$ è però la parte reale di $s$, mentre $\sigma_i$ la reale di $\lambda_i$, dunque possiamo sostituire i primi termini a questi ultimi e ottenere che: \[\forall s\in \mathbb{C}, Re(s) > Re(\lambda_i)\]
	\noindent Di conseguenza, il semipiano positivo è composto da tutti quei valori di $s$ che devono necessariamente essere maggiori o uguali delle radici.
\end{dimostrazione}
\noindent Notare infine che per un sistema LTI stabile, la regione di convergenza conterrà sempre anche l'asse immaginario. Passiamo ora alle \textbf{proprietà} della TdL:
\begin{itemize}
	\item \textbf{Linearità}\par
	\noindent Siano $v_1, v_2$ funzioni che ammettono TdL e rispettivamente $V_1, V_2$ le loro trasformate. Avremo che $av_1(t) + bv_2(t)$ ammette TdL. Invece, per l'ascisse di convergenza si prenderà il valore più alto fra le due, quindi, in tutto avremo: \[\mathcal{L}[av_1(t) + bv_2(t)](s) = aV_1(s) + bV_2(s); \alpha \geq max\{\alpha_1, \alpha_2\}\]
	\item \textbf{Traslazione nel dominio del tempo}\par
	\noindent Sia $v(t)$ funzione che ammette TdL; traslandola avremo $v(t-\tau)$, la quale continuerà ad ammettere la trasformata solamente con $\tau > 0$. In tal caso definiamo: \[\mathcal{L}[v(t-\tau)](s) = e^{-st}L[v(t)](s)\]
	\noindent La regione di convergenza con questa proprietà rimane immutata.
	\item \textbf{Traslazione nel dominio dei complessi}\par
	\noindent Parliamo quindi di moltiplicazioni per una funzione esponenziale complessa. Sia $v(t)$ che ammette TdL, allora ciò varrà anche per $e^{\lambda t}v(t)$ e descriveremo la trasformata come \[\mathcal{L}[e^{\lambda t}v(t)](s) = V(s-\lambda)\]
	\noindent In questa proprietà, la regione di convergenza viene spostata, di conseguenza, anche l'ascissa diventa \[\alpha = \alpha_0 + Re(\lambda)\]
	\noindent Con $\lambda$ esponenziale qualsiasi.
	\item \textbf{Cambio di scala}\par
	\noindent Sia $v(t)$ che ammette TdL, allora anche $v(rt)$ ammette TdL, la quale è definita come \[\mathcal{L}[v(rt)](s) = \frac{1}{r} V\left(\frac{s}{r}\right)\]
	\item \textbf{Comportamento con le derivate}\par
	\noindent Sia $v(t)$ che ammette TdL ed un limite finito $v(0^-) = \lim_{t\to 0^-} v(t)$. Allora anche la derivata i-esima della funzione ammette TdL. \[L\left[\frac{d^iv(t)}{dt^i}\right] = s^iV(s) - \sum_{k=0}^{i-1} \left[\frac{d^kv(t)}{dt^k}\right]_{t=0^-} (s^{i-1-k})\]
	\noindent L'ascissa di convergenza qui è $\alpha \leq \alpha_0$, con $\alpha_0$ ascisse originale. Essendo una proprietà importante, dimostriamone il funzionamento per derivata prima e seconda.
	\begin{dimostrazione}
		\textbf{Dimostrazione per derivata prima}
		\begin{equation}
			\begin{split}
				\mathcal{L}\left[\frac{dv(t)}{dt}\right](s) &= \int_{0^-}^{+\infty}\frac{dv(t)}{dt}e^{-st} dt\\
				&= v(t)e^{-st}\Big|_{0^-}^{+\infty} -\left(-s\int_{0^-}^{+\infty}v(t)e^{-st}dt\right)\\
				&= \lim_{\epsilon\to \infty} v(\epsilon)e^{-s\epsilon} - \lim_{\epsilon\to 0^-}v(\epsilon)e^{-s\epsilon} + sV(s)\\
				&= sV(s) - v(0^-)
			\end{split}
		\end{equation}
	\end{dimostrazione}
	\begin{dimostrazione}
		\textbf{Dimostrazione per derivata seconda}
		\begin{equation}
			\begin{split}
				\mathcal{L}\left[\frac{d^2v(t)}{dt^2}\right](s) &= L\left[\frac{d}{dt}\left(\frac{dv(t)}{dt}\right)\right](s)\\
				&= s\mathcal{L}\left[\frac{d}{dt}v(t)\right](s) - \frac{dv(t)}{dt}\Big|_{t=0^-}\\
				&= s(s\mathcal{L}[v(t)](s) - v(0^-)) - \frac{dv(t)}{dt}\Big|_{t=0^-}\\
				&= s^2V(s) - sv(0^-) - \frac{dv(t)}{dt}\Big|_{t=0^-}
			\end{split}
		\end{equation}
	\end{dimostrazione}
	\item \textbf{Moltiplicazione per funzione polinomiale}\par
	\noindent Sia $v(t)$ che ammette TdL, allora lo farà anche $t^iv(t)$. \[\mathcal{L}[t^iv(t)] = (-1)^i\frac{d^iV(s)}{ds^i}\]
	\begin{dimostrazione}
		\begin{equation}
			\begin{split}
				\mathcal{L}[tv(s)](s) &= \int_{0^-}^{+\infty} tv(t) e^{-st}dt = -\int_{0^-}^{+\infty} v(t) (-te^{-st}) dt\\
				&= -\int_{0^-}^{+\infty} v(t) \frac{de^{-st}}{ds} dt = -\frac{d}{ds}\int_{0^-}^{+\infty} v(t)e^{-st} dt\\
				&= -\frac{d}{ds}V(s)
			\end{split}
		\end{equation}
	\end{dimostrazione}
	\item \textbf{Integrazione nel dominio del tempo}\par
	\noindent Sia $v(t)$ che ammette TdL, e se è definito $\psi(t) = \int_{0^-}^t v(t) dt$ suo integrale nel tempo, allora anche quest'ultimo ammette TdL. Qui l'ascissa di convergenza è il massimo fra $0$ ed $\alpha_0$. \[\mathcal{L}\left[\int_{0^-}^{\tau} v(t) d\tau\right](s) = \frac{V(s)}{s}\]
	\begin{dimostrazione}
		\begin{equation}
			\begin{split}
				v_i(t) &= \int_{0^-}^t v(\tau) d\tau \implies v_1'(t) = v(t) \land v(0^-) = \int_{0^-}^{0^-} v(\tau) d\tau = 0\\
				&= \mathcal{L}[v(t)](s) = \mathcal{L}[v_1'(t)](s) \implies s\mathcal{L}[v_1'(t)](s) - v_1(0^-)\\
				&= v_1(0^-) = 0 \implies s\mathcal{L}\left[\int_{0}^t v(\tau) d\tau\right](s)\\
				&= \mathcal{L}\left[\int_{0}^t v(\tau) d\tau\right] = \frac{V(s)}{s}
			\end{split}
		\end{equation}
	\end{dimostrazione}
	\item \textbf{Integrazione nel dominio dei complessi}\par
	\noindent Sia $v(t)$ che ammette TdL ed esistente $\lim_{t\to 0^-} \frac{v(t)}{t}$, allora vale: \[\mathcal{L}\left[\frac{v(t)}{t}\right](s) = \int_s^{\infty} \mathcal{L}[v(t)](\sigma) d\sigma\]
	\item \textbf{Teorema del valore iniziale}\par
	\noindent Questa proprietà permette di capire il comportamento asintotico della funzione in $0$, poiché ritorna il limite della derivata prima in condizioni nulle.
	Sia $v(t)$ che ammette TdL ed esistente finito il $\lim_{t\to 0^-}v(t)$, allora vale:
	\[\lim_{t\to 0^-} v(t) = \lim_{s\to \infty} s\mathcal{L}[v(t)](s)\]
	\item \textbf{Teorema del valore finale}\par
	\noindent Questa proprietà permette di capire il comportamento asintotico della funzione in infinito guardando il limite in $0^+$. Sia $v(t)$ che ammette TdL ed esistente finito il $\lim_{t\to \infty} v(t)$, allora:
	\[\lim_{t\to \infty}v(t) = \lim_{s\to 0^+} s\mathcal{L}[v(t)](s)\]
	\item \textbf{Convoluzione nel dominio del tempo}\par
	\noindent siano $u(t)$ e $v(t)$ due funzioni generiche e causali nulle per $t<0$ e che ammettono TdL. Allora anche $(u*v)(t)$ ammetterà TdL e varrà: \[\mathcal{L}[(u*v)(t)](s) = \mathcal{L}[u(t)](s) \times \mathcal{L}[v(t)](s)\]
	\begin{dimostrazione}
		\begin{equation}
			\begin{split}
				\mathcal{L}[(u*v)(t)](s) &= \int_{0^-}^{+\infty} \left(\int_{-\infty}^{+\infty}u(\lambda)v(t-\lambda) d\lambda\right)e^{-st} dt\\
				&= \int_{0^-}^{\infty}\int_{0^-}^{\infty} u(\lambda)v(t-\lambda)e^{-st} dt d\lambda\\
				&= \int_{0^-}^{\infty} u(\lambda)\left(\int_{0^-}^{+\infty} v(t-\lambda)e^{-st} dt\right) d\lambda
			\end{split}
		\end{equation}
		\noindent Sostituiamo ora: $x=t-\lambda$, $t=x+\lambda$, $dt=dx$, otteniamo:
		\begin{equation}
			\begin{split}
				\mathcal{L}[(u*v)(t)](s) &= \int_{0^-}^{\infty} u(\lambda)\left(\int_{0^-}^{+\infty} v(x)e^{-s(x+\lambda)} dx\right) d\lambda\\
				&= \int_{0^-}^{+\infty} u(\lambda)e^{-s\lambda} d\lambda\int_{0^-}^{+\infty} v(x)e^{-sx} dx\\
				&= \mathcal{L}[u(t)](s)\mathcal[v(t)](s)
			\end{split}
		\end{equation}
	\end{dimostrazione}
\end{itemize}

%

\section{Trasformate notevoli}
Viste le proprietà e capito il procedimento generale, possiamo ora mostrare quelle che sono le trasformate più di comune utilizzo; annotarle è necessario poiché consentono di trasformare le funzioni in modo più veloce. Ricordare che la funzione può essere anche traslata per tempo e avere ampiezze diverse, quindi esistono trasformate anche per questi due casi. Ringrazia le proprietà di linearità e ritardo nel tempo.\newline

\noindent$\bullet$ \textbf{Trasformata dell'impulso} $\delta_0(t)$:
\begin{itemize}
	\item Condizione basilare: \[\mathcal{L}[\delta_0(t)](s) = \int_{0^-}^{\infty}\delta(t)e^{-st} dt = e^{-st}\Big|_{t=0} = 1\]
	\item Ampiezza considerata: \[\mathcal{L}[A\delta_0(t)](s) = A\mathcal{L}[\delta_0(t)](s) = A\times 1 = A\]
	\item Funzione traslata nel tempo: \[\mathcal{L}[\delta_0(t-\tau)](s) = e^{-s\tau}\mathcal{L}[\delta_0(t)](s) = e^{-s\tau}\]
\end{itemize}

\noindent$\bullet$ \textbf{Trasformata del gradino} $\delta_{-1}(t)$:
\begin{itemize}
	\item Condizione basilare:
	\begin{equation}
		\begin{split}
			\mathcal{L}[\delta_{-1}(t)](s) &= \int_{0^-}^{+\infty}\delta_{-1}(t)e^{-st} dt = \int_{0^-}^{+\infty} e^{-st} dt\\
				&= \lim_{\epsilon\to\infty; \mu\to 0^-}\left(-\frac{e^{st}}{s}\right)\Big|_{t=\mu}^{\epsilon}\\
				&= \lim_{\mu\to 0^-}\frac{e^{-st}}{s} - \lim_{\epsilon\to \infty}\frac{e^{-st}}{s} = \frac{1}{s}
		\end{split}
	\end{equation}
	\item Ampiezza considerata: \[\mathcal{L}[A\delta_{-1}(t)](s) = \frac{A}{s}\]
	\item Funzione traslata nel tempo: \[\mathcal{L}[\delta_{-1}(t-\tau)](s) = \frac{e^{-s\tau}}{s}\]
\end{itemize}

\noindent$\bullet$ \textbf{Esponenziale complesso causale} $v(t) = e^{\lambda t}\delta_{-1}(t)$:
\begin{itemize}
	\item Condizione basilare: \[\mathcal{L}[e^{\lambda t}\delta_{-1}(t)](s) = \mathcal{L}[\delta_{-1}(t)](s-\lambda) = \frac{1}{s-\lambda}\]
	\item Ampiezza considerata: \[\mathcal{L}[Ae^{\lambda t}\delta_{-1}(t)](s) = \frac{A}{s-\delta}\]
	\item Funzione traslata nel tempo: \[\mathcal{L}[e^{\lambda(t-\tau)}\delta_{-1}(t-\tau)](s) =  \frac{e^{-(s-\lambda)\tau}}{s-\delta}\]
\end{itemize}

\noindent$\bullet$ \textbf{Esponenziale complesso causale moltiplicato per una funzione polinomiale} $v(t) = \frac{t^l}{l!}e^{\lambda t}\delta_{-1}(t)$:
\begin{itemize}
	\item Condizione basilare:
	\begin{equation}
		\begin{split}
			\mathcal{L}\left[\frac{t^l}{l!}e^{\lambda t}\delta_{-1}(t)\right](s) &= \frac{1}{l!}\times \mathcal{L}[t^le^{\lambda t}\delta_{-1}(t)](s)\\
			&= \frac{(-1)^l}{l!}\times\frac{l^l}{ds^l}\times\mathcal{L}[e^{\lambda t}\delta_{-1}(t)](s)\\
			&= \frac{(-1)^l}{l!}\times\frac{l^l}{ds^l}\left(\frac{1}{s-\lambda}\right)\\
			&= \frac{(-1)^l}{l!}\times\frac{l!(-1)^l}{(s-\lambda)^{l+1}}\\
			&= \frac{1}{(s-\lambda)^{l+1}}
		\end{split}
	\end{equation}
	\item per $l=1$: \[\mathcal{L}[te^{\lambda t}\delta_{-1}(t)](s) = \frac{1}{(s-\lambda)^2}\]
	\item per $l=2$: \[\mathcal{L}\left[\frac{t^2}{2!}e^{\lambda t}\delta_{-1}(t)\right](s) = \frac{1}{(s-\lambda)^3}\]
	\item Manca il primo esponenziale: \[\mathcal{L}\left[\frac{t}{l!}\delta_{-1}(t)\right](s) = \frac{1}{s^{l+1}}\]
	\item Manca il secondo esponenziale: \[\mathcal{L}[t\delta_{-1}(t)](s) = \frac{l!}{s^{l+1}}\]
	\item Manca il polinomio: \[\mathcal{L}[e^{-\lambda t}\delta_{-1}(t)](s) = \frac{1}{s+\lambda}\]
\end{itemize}

\noindent$\bullet$ \textbf{Trasformata per famiglie sinusoidali - Coseno}:
\begin{equation}
	\begin{split}
		\mathcal{L}[cos(\omega t)](s) &= \mathcal{L}\left[\frac{e^{j\omega t}-e^{-j\omega t}}{2}\right](s) = \frac{1}{2}\mathcal{L}[e^{j\omega t} + e^{-j\omega t}](s)\\
			&= \frac{1}{2}\left(\frac{1}{s-j\omega} + \frac{1}{s+j\omega}\right) = \frac{1}{2}\left(\frac{s}{s^2+\omega^2}\right)
	\end{split}
\end{equation}

\noindent$\bullet$ \textbf{Trasformata per famiglie sinusoidali - Seno}:
\begin{equation}
	\begin{split}
		\mathcal{L}[sin(\omega t)](s) &= \mathcal{L}\left[\frac{e^{j\omega t} - e^{-j\omega t}}{2j}\right](s) = \frac{1}{2j}(\mathcal{L}[e^{j\omega t}](s) - \mathcal{L}[e^{-j\omega t}](s))\\
			&= \frac{1}{2j}\left(\frac{1}{s - j\omega} - \frac{1}{s+j\omega}\right) = \frac{1}{2j}\left(\frac{s + j\omega - s + j\omega}{s^2+\omega^2}\right)\\
			&= \frac{\omega}{s^2 + \omega^2}
	\end{split}
\end{equation}

%

\section{Utilizzo della TdL per il calcolo delle risposte}
Come già detto, il passaggio a funzione trasformata è uno step per ottenere la risposta totale, e quindi anche la libera, impulsiva e forzata. Bisogna prima fare dei passi iniziali per ottenere gli strumenti di lavoro della sezione. Richiamiamo quindi alla memoria la scrittura descrivente un sistema: \[\sum_{i=0}^n a_i \frac{d^iv(t)}{dt^i} = \sum_{j=0}^m b_j\frac{d^j u(t)}{dt^j}\]
\noindent Supponiamo ora il grado degli input $n$ maggiore di quello degli output $m$, con $u(t) = u(t)\delta_{-1}(t)$, con le seguenti condizioni iniziali: \[v(0^-); \frac{dv(0^-)}{dt}; ...; \frac{d^{n-1}v(0^-)}{dt^{n-1}}\]
\noindent Se $u(t)$ ammette TdL, allora lo farà anche $v(t)$, per $t\geq 0$. Siano ora $U(s)$ e $V(s)$ le TdL di $u(t)$ e $v(t)$ rispettivamente. Il modello si può riscrivere come: \[\mathcal{L}\left[\sum_{i=0}^n a_i \frac{d^iv(t)}{dt^i}\right](s) = \mathcal{L}\left[\sum_{j=0}^m b_j\frac{d^j u(t)}{dt^j}\right](s)\]
\noindent Da qui possiamo effettuare alcuni passaggi algebrici grazie alla proprietà viste nella sezione precedente:
\begin{itemize}
	\item Tiriamo fuori le costanti: \[\sum_{i=0}^n a_i \mathcal{L}\left[\frac{d^i v(t)}{dt^i}\right](s) = \sum_{j=0}^n b_j \mathcal{L}[\frac{d^ju(t)}{dt^j}](s)\]
	\item Applichiamo $n+m$ volte la regola della derivata: \[a_n\left[s^nV(s) - \sum_{k=0}^{n-1} \frac{d^kv(t)}{dt^k}\Big|_{t=0^-} (s^{h-1-k})\right] + a_{n-1}\left[s^{n-1}V(s) - \sum_{k=0}^{n-2} \frac{d^kv(t)}{dt^k}\Big|_{t=0^-}(s^{h-2-k})\right] + ... + a_0V(s)\]
	\item Imponiamo le CE iniziali per $u(t)\big|_{t=0^-} = 0$: \[b_ms^mU(s) + b_{m-1}s^{m-1}U(s) + ... + b_0U(s)\]
	\item Espandiamo le sommatorie e raccogliamo: \begin{equation}
		\begin{split}
			& (a_ns^n + a_{n-1}s^{n-1} + ... + a_0)V(s) +\\
			&- a_nv(0^-)s^{n-1} - \left(a_{n-1}v(0^-) + a_n\frac{dv(t)}{dt}\Big|_{t=0}\right)s^{n-2} - ... - \left(\sum_{k=0}^{n-1} a_{k+1}\frac{d^kv(t)}{dt^k}\Big|_{t=0^-}\right)\\
			&= (b_ms^m + b_{m-1}s^{m-1} + ... + b_0)U(s).
		\end{split}
	\end{equation}
\end{itemize}
\noindent Questa è una scrittura enorme, ragion per cui da qui in poi verrà abbreviata per garantirne un riutilizzo più semplice con: \[d(s)V(s) - p(s) = n(s)U(s)\]
\noindent Le componenti sono:
\begin{itemize}
	\item $d(s) = (a_ns^n + a_{n-1}s^{n-1} + ... + a_0)$, è un polinomio di grado $n$, il quale dipende solo dai coefficienti delle derivate associate all'uscita. È anche il polinomio caratteristico di $v(t)$.
	\item $p(s) = a_nv(0^-)s^{n-1} - (a_{n-1}v(0^-) + a_n\frac{dv(t)}{dt}|_{t=0})s^{n-2} - ... - (\sum_{k=0}^{n-1} a_{k+1}\frac{d^kv(t)}{dt^k}|_{t=0^-}$, si tratta di un polinomio di grado $n-1$ che contiene le condizioni iniziali.
	\item $n(s) = (b_ms^m + b_{m-1}s^{m-1} + ... + b_0)$, polinomio di grado $m$. È anche il polinomio caratteristico di $u(t)$.
\end{itemize}
\noindent Questa forma ci semplifica enormemente le cose, permettendoci di ricavare più facilmente le varie componenti della risposta totale con le seguenti formule:
\begin{itemize}
	\item \textbf{Risposta totale} \[V(s) = \frac{n(s)}{d(s)}U(s) + \frac{p(s)}{d(s)}\]
	\item \textbf{Risposta libera} \[V_l(s) = \frac{p(s)}{d(s)}\]
	\item \textbf{Risposta forzata} \[V_f(s) = \frac{h(s)}{d(s)}U(s)\]
	\item \textbf{Risposta impulsiva} o funzione di trasferimento \[H(s) = \frac{\sum_{j=0}^m b_js^j}{\sum_{i=0}^na_is^i}\]
\end{itemize}
\begin{esempio}
	\textbf{Dato il sistema $v'''(t) + v''(t) = u(t)$, trovare la risposta totale $V_t(s)$}\par
	\noindent Per raggiungere la forma semplificata, è necessario effettuare passaggi algebrici ed ottenere la formula per $V_t(s)$. Grazie alla proprietà della linearità possiamo applicare la trasformata un elementoper volta, dunque:
	\begin{equation}
		\begin{split}
			\left(s^3V(s) - s^2v(0^-) - s^1\frac{dv(0)^-}{dt} - s^0\frac{d^2v(0^-)}{dt}\right) + \left(s^2V(s) - sv(0^-) - s^0\frac{dv(0^-)}{dt}\right) &= sU(s)\\
			(s^3+s^2)V(s) - \left[s^2v(0^-) + s\frac{dv(0)^-}{dt} + \frac{d^2v(0^-)}{dt} + sv(0^-) + \frac{dv(0^-)}{dt}\right] &= sU(s)			
		\end{split}
	\end{equation}
	\noindent Spostando infine gli elementi per ricavare $V_t(s)$, otteniamo quanto richiesto: \[V(s) = \frac{s}{s^3+s^2}U(s) + \frac{s^2v(0^-) + s(\frac{dv(0^-)}{dt}+v(0^-)) + (\frac{d^2v(0^-)}{dt^2}+\frac{dv(0^-)}{dt})}{s^3+s^2}\]
	\noindent L'esercizio qui è puramente per mostrare il procedimento; in questo momento si dovrebbero applicare le condizioni di Cauchy.
\end{esempio}


\begin{comment}	
		H(s), che è la TdL della risposta impulsiva, si dice anche funzione di trasferimento. Già scritta nella lezione precedente. Si tratta di una funzione razionale il cui numeratore ha grado generalmente minore o uguale a quello del denominatore, quindi:
		- q\leq m; \sum \xi_i = m
		- r\leq n; \sum \mu_i = n
		Se proviamo a fattorizzarla, otterremo \[\frac{b_m(s-\beta_1)^{\xi_1}(s-\beta_2)^{\xi_2} ... (s-\beta_q)^{\xi_q}}{a_n(s-\alpha_1)^{\mu_1}(s-\alpha_2)^{\mu_2} ... (s-\alpha_r)^{\mu_r}}\]
		Le \xi sono le molteplicità delle soluzioni del numeratore
		Le \mu sono quelle del denominatore
		Le \beta e le \alpha fra le tonde sono rispettivamente radici del numeratore e del denominatore.
		Otteniamo una scrittura più pulita: \[H(s) = k\frac{(s-z_1)(s-z_2) ... (s-z_m)}{(s-p_1)(s-p_2) ... (s-p_n)}\]
		Qui i fattori a numeratore si dicono zeri della funzione razionale, mentre quelli a denominatore sono i poli. Entrambi sono le radici dei polinomi rispettivi, ovviamente.
		
		Definiamo poi uno zero di una funzione razionale H(s) un qualsiasi numero \beta\in C tale per cui H(\beta) = 0.
		Un polo di una funzione razionale H(s) è invece un qualsiasi numero \alpha\in C tale per cui H(\alpha) = \infty.
		
		Accorciamo ulteriormente, k=\frac{bm}{an}
		
		Ora, grazie alla funzione di trasferimento possiamo fare asserzioni sulla stabilità.
		Supponiamo H(s) in forma ridotta, quindi con radici in comune rimosse.
		Siano \lambda_i, ..., \lambda_r; r\leq n i suoi poli post-semplificazione.
		Se la parte reale delle \lambda_i è minore di 0, con le i che vanno da 1 a r, possiamo dire che il sistema è bibostabile. (Questa cosa evita di calcolare integrali, è importante)
		Quindi un sistema è bibostabile se tutti i suoi poli giacciono nel semipiano complesso negativo.
		È possibile anche bibostabilizzare un sistema; bisogna rimuovere gli zeri \lambda_i con parte reale maggiore di 0, quindi dividendoli per poli uguali. Così andremo a rispettare la definizione.
		
		Esempio: v'(t) - 3v(t) = u''(t) - 5u'(t) + 4u(t).
		Notare che qui n < m, in genere è l'opposto.
		
		Vogliamo vedere se è stabile o no, quindi per prima cosa passiamo al polinomio caratteristico
		s-3 = s^2-5s+4
		
		Troviamo H(s).
		H(s) = \frac{n(s)}{d(s)} = \frac{pol caratteristico d'ingresso}{" d'uscita} = \frac{s^2-5s+4}{s-3}
		
		Fattorizziamolo.
		\frac{(s-1)(s-4)}{s-3}
		A denominatore abbiamo \lambda_1 = 3, mi fa capire che il sistema non è asintoticamente stabile perché ha parte reale maggiore di 0.
		
		Per vedere se è bibostabile proviamo a semplificare i termini con questo problema. Tuttavia noterai che non possiamo fare un cazzo, quindi rimane instabile.
		
		Esempio: v''(t) + 3v'(t) + 2v(t) = u''(t) - 4u'(t) + 3u(t)
		1. Polinomio caratteristico
		\[s^2 + 3s + 2 = s^2 - 4s + 3\]
		2. Ricaviamo H(s)
		\[H(s) = \frac{s^2 - 4s + 3}{s^2 + 3s + 2}\]
		3. Fattorizziamo i polinomi
		\[H(s) = \frac{(s-3)(s-1)}{(s+1)(s+2)}\]
		4. Controlla re(\lambda_i) < 0
		\lambda_1 = -1, \lambda_2 = -2. Il sistema è asintoticamente stabile.
		Come conseguenza diretta, il sistema è anche bibostabile.
		
		Esempio: v'''(t) + 7v''(t) - 2v'(t) + 6v(t) = u''(t) + 3u'(t) - 4u(t)
		1,2. Polinomio caratteristico per H(s)
		\[H(s) = \frac{s^2+3s-4}{s^3+7s^2-2s+6}\]
		3. Fattorizzazione
		\[H(s) = \frac{(s+4)(s-1)}{(s+3)(s+2)(s-1)}\]
		\lambda_3 = +1. Non è asintoticamente stabile. Tuttavia, semplificandolo, si rimuove proprio questo fattore, rendendo il sistema bibostabile.
\end{comment}

\section{Antitrasformata di Laplace unilatera}

\begin{comment}
	--- Antitrasformata di laplace unilatera
	Presupponiamo di aver fatto tutte le trasformazioni e di aver ottenuto la forma V(s) = \frac{n(s)}{d(s)}, la risposta del nostro sistema in laplace. Abbiamo due vie.
	- Se il grado di n(s) \geq al grado di d(s):
	Diciamo che questo è un sistema proprio. Dobbiamo fare una divisione polinomiale, poi fratti semplici ed infine l'antitrasformata, che grazie alla sua linearità, si può applicare alle singole componenti dell'equazione.
	
	- Divisione polinomiale:
	Ci fa ottenere V(s) = \frac{r(s)}{d(s)}+k, dove il grado di r(s) < di quello di d(s), con k\in C.
	Il procedimento è semplice; bisogna trovare una costante da moltiplicare al polinomio divisore tale per cui, quando questo è sottratto al dividendo, scompaia il termine di grado più alto. Per esempio:
	\[\frac{2s^2 + 4s - 3}{s^2 - s - 1}\]
	In questo caso possiamo moltiplicare 2 al polinomio del denominatore.
	Sottraendo il numeratore a questo nuovo denominatore otteniamo $6s-1$.
	Quindi la nuova forma di V(s) è: \[\frac{6s-1}{s^2-s-1}+2\]
	
	- Decomposizione in fratti semplici
	Consente di andare a riscrivere \frac{r(s)}{d(s)} come sommatoria di frazioni, la quale ha forma \[\sum_{i=1}^r\sum_{l=0}^{\mu_1-1}\frac{c_{i,l}}{(s-\alpha_i)^{l+1}}\]
	Che guarda caso è la forma di una trasformata notevole. Come si fa?
	Usare la formula: \[c_{i,l} = lim_{s\to \alpha_i}\frac{d^{\mu_i-l-1}((s-\alpha_i)^{\mu_i}\frac{r(s)}{d(s)})}{ds^{\mu_i-l-1}}\]
	
	Esempio: V(s) = \frac{s-20}{(s+4)(s-2)}.
	Qui abbiamo \alpha_1=-4;\alpha_2=2, con entrambi i gradi \mu_1=\mu_2=1
	Scomponiamo in fratti semplici:
	\[\frac{A}{s+4} + \frac{B}{s-2}\] Ora abbiamo due scelte:
	1. Svolgere calcoli a fattor comune (sconsigliato)
	2. Formula del porcodiodilimite, usata per ogni singolo c:
	- c_{1,0} = A, che ha \mu=1;\alpha=-4
	A = lim_{s\to-4}\frac{d^{1-0-1}((s+4)^1 \frac{s-20}{(s+4)(s-2)})}{d^{1-0-1}} = \frac{d^0((-4+4)^1 \frac{-4-20}{(-4+4)(-4-2)})}{d^0} = \frac{-24}{-6} = 4.
	- c_{2,0} = B, che ha \mu=1;\alpha=2
	B = lim_{s\to 2}\frac{d^{1-0-1}((s-2)^1\frac{s-20}{(s+4)(s-2)})}{d^{1-0-1}} = -\frac{18}{6} = 3
	
	Quindi i fratti semplici diventano: \[V(s) = \frac{s-20}{(s+4)(s-2)} = \frac{4}{s+4} + \frac{3}{s-2}\]
	
	- Applicazione dell'antitrasformata
	Abbiamo quindi una forma V(s) = k+\sum_{i=1}^r\sum_{l=0}^{\mu_1-1} \frac{c_{i,l}}{(s-\lambda_i)^{l+1}}
	Andando indietro con le trasformate abbiamo:
	v(t) = \mathcal{L}[k](t) + \sum_{i=1}^r\sum_{l=0}^{\mu_1-1} c_{i,l}\mathcal{L}[\frac{1}{(s-\lambda_i)^{l+1}}](t)
	Che ci fa ottenere.
	k\delta_0(t) + \sum_{i=1}^r\sum_{l=0}^{\mu_1-1} c_{i,l}\frac{t^l}{l!}e^{\lambda_i t}\delta_{-1}(t)
	
	
	
	- Se il grado di n(s) < al grado di d(s):
	Diciamo che questo è un sistema strettamente proprio, si salta la divisione polinomiale e si fanno gli altri due passaggi.
\end{comment}