Onestamente non ho la benché minima idea di cosa tratti matematica di base; tutti gli argomenti sembrano familiari ma allo stesso tempo estranei. Inoltre sembra una materia di cui si sente la mancanza nell'ordinamento precedente. Iniziamo con la definizione formale di \textbf{Insieme}, elemento della teoria su cui si basa la matematica tutta:
\begin{definition}
    \textbf{Insieme}\par
    Gruppo di elementi aventi una stessa proprietà. Si indica con una lettera maiuscola.
\end{definition}
Pare ovvio che con questi insiemi sia possibile operare in qualche modo; per prima cosa elenchiamo i simboli utilizzati nel corso:\par
\textbf{Connettivi}:
\begin{itemize}
    \item \textbf{Congiunzione}: $\land$\par
    Ritorna vero solo se tutti gli elementi sono veri.
    \item \textbf{Disgiunzione}: $\lor$\par
    Ritorna vero se almeno un elemento è vero.
    \item \textbf{Negazione}: $\neg$\par
    Rende falso il vero e viceversa.
    \item \textbf{Implicazione}: $\implies$\par
    Corrisponde a "Se, allora", ritorna vero nei casi $0 \to 1$ oppure $1 \to 1$, mentre è falso se $1 \to 0$ oppure $0 \to 0$.
    \item \textbf{Doppia Implicazione}: $\iff$\par
    Corrisponde a "se e solo se, allora" e viene rappresentata mediante due implicazioni: $(\phi \to \psi) \land (\psi \to \phi)$.
    \item \textbf{Bottom}: $\bot$\par
    Indica il valore di assurdo, $0$.
\end{itemize}
\textbf{Quantificatori}:
\begin{itemize}
    \item \textbf{Esiste}: $\exists$\par
    Indica l'esistenza di un elemento con una determinata proprietà. Normalmente si usa legato ad una proprietà di un elemento, quindi per dimostrarlo serve quest'ultimo e la prova di tale proprietà.
    \item \textbf{Per ogni}: $\forall$\par
    Indica che per ogni caso considerato, esiste un elemento con una data proprietà. Per dimostrarlo serve supporre un elemento e trovare una prova della proprietà ad esso associata.
\end{itemize}
Dai connettivi e i quantificatori abbiamo anche i seguenti assiomi logici:
\begin{itemize}
    \item \textbf{Tautologie}\par
    Formule che risultano vere in ogni istanza presa in esame. Un esempio di tautologia sono le leggi di De Morgan, fondamentali per l'insiemistica.
    \begin{definition}
        \textbf{Tautologia}\par
        \begin{itemize}
            \item \textbf{Semplice}:\par
            Data una formula $P$ abbiamo che $P\implies P$ è sempre vera, quindi una tautologia. Per dimostrarla troviamo una prova di $P$ e hai fatto.
            \item \textbf{Modus Ponens}:\par
            Se $P, Q$ sono due formule, allora $(P\implies Q) \implies (\neg Q \implies \neg P)$ è tautologia. Per dimostrarla è necessario trovare le prove di ambo le ipotesi, dopodiché supponi le prove per $[\neg P := (P \implies \bot)]$ e $[\neg Q := (Q \implies \bot)]$.\par
            Supponi ora $P$. Da $P\implies Q$ traiamo $Q$, dalla quale possiamo trarre $Q \implies \bot$, quindi $\bot$. La formula quindi vale perché dall'assurdo si può derivare qualunque cosa.
        \end{itemize}
    \end{definition}
    \item \textbf{Principio del terzo escluso} - $PEM_P$:\par
    Data la formula $(P \lor \neg P)$, non c'è nessun altro elemento fra $P \land \neg P$ o $P \lor \neg P$.
    \begin{prop}
        \textbf{Principio del terzo escluso}
        \begin{center}
            $(P \lor \neg P)$.
        \end{center}
    \end{prop}
    \item \textbf{Eliminazione della doppia negazione} $DNE_P$:\par
    Dall'assurdo possiamo derivare qualunque cosa, di conseguenza possiamo derivare una formula $P$ da $\bot$.
    \begin{prop}
        \textbf{Eliminazione della doppia negazione}\par
        \begin{center}
            $\neg\neg P \implies P := \neg P \implies \bot := (P \implies \bot) \implies \bot$.
        \end{center}
    \end{prop}
\end{itemize}
Da questi ultimi due assiomi logici traiamo anche le seguenti formule vere, la cui dimostrazione è lasciata per esercizio:
\begin{enumerate}
    \item $PEM_P \implies DNE_P$.
    \item $\neg\neg P \implies P$.
    \item $(\neg Q \implies \neg P) \implies (P \implies Q)$.
\end{enumerate}
Ed ora introduciamo tutte le varie operazioni insieme alle loro proprietà.

\section{Operazioni fra gli insiemi}
Distinguiamo inizialmente i due casi in cui è possibile operare con gli insiemi:
\begin{itemize}
    \item \textbf{Coppie}, collezioni di oggetti dove è possibile distinguere il primo elemento dal secondo. Si distinguono in:
    \begin{itemize}
        \item \textbf{Ordinate}: $(A, B) = \{\{x\}, \{x, y\}\}$\par
        Insieme dove gli elementi sono legati da una determinata relazione di ordinamento.
        \item \textbf{Non ordinate}: $(A, B) = (B, A)$\par
        Gli insiemi di questo tipo saranno sempre uguali se contengono gli stessi identici elementi, a prescindere dall'ordine in cui sono scritti.
    \end{itemize}
    \item \textbf{N-uple}, dove sono presenti più di due insiemi, trattato più avanti.
\end{itemize}
Ed ora possiamo iniziare con le operazioni effettive:
\begin{itemize}
    \item \textbf{Appartenenza, contenimento e sottoinsieme}\par
    Diciamo che un elemento $x$ appartiene ad un insieme $A$ quando rispetta i criteri per farne parte, come avere una determinata proprietà o caratteristica.
    \begin{definition}
        \textbf{Appartenenza e non appartenenza}\par
        Data una proprietà $P$ requisito per far parte dell'insieme $A$, definiamo formalmente:
        \begin{itemize}
            \item \textbf{Appartenenza}: $x \in A$, $A = \{x | P(x)\}$\par
            All'insieme $A$ appartiene l'elemento $x$ tale che $x$ abbia una data proprietà P.
            \item \textbf{Non appartenenza}: $y \notin A$\par
            All'insieme $A$ non appartiene $y$.
        \end{itemize}
    \end{definition}
    Diremo poi che un insieme $B$ è sottoinsieme di $A$ quando il primo è interamente contenuto nel secondo. Ciò non necessariamente significa che sia uguale, tuttavia.
    \begin{definition}
        \textbf{Sottoinsiemi}\par
        Dati due insiemi $A$ e $B$ diremo che $B$ possiamo avere i seguenti casi:
        \begin{itemize}
            \item \textbf{Sottoinsieme improprio}: $B \subseteq A \iff \forall x.(x \in A \implies x \in B)$\par
            Quando ogni elemento appartiene a $B$, appartiene anche ad $A$.
            \item \textbf{Uguaglianza}: $A = B \iff \forall x.(x \in A \iff x \in B)$\par
            Quando due insiemi sono perfettamente uguali.
            \item \textbf{Sottoinsieme proprio}: $B \subset A$\par
            Quando tutti gli elementi di $B$ appartengono ad $A$ e $A \neq B$.
        \end{itemize}
    \end{definition}
    Abbiamo infine l'elemento neutro, detto \textbf{Insieme Vuoto}, scritto con $A = \emptyset$, il quale indica un insieme privo di elementi; è sottoinsieme di tutti gli insiemi, perché di base ogni collezione di elementi contiene il vuoto, il quale verrà riempito con questi ultimi.
    \item \textbf{Unione}\par
    L'unione fra due insiemi risulta come un terzo insieme contenente gli elementi di entrambi. Formalmente:
    \begin{definition}
        \textbf{Unione} $A \cup B = \{a | a \in A \lor a \in B\} = C$\par
        Unisce gli elementi di $A$ a quelli di $B$ per creare un nuovo insieme $C$ che contiene tutti gli elementi dei primi due senza ripetizioni. Detiene inoltre le seguenti proprietà:
        \begin{itemize}
            \item $A \cup \emptyset = A$
            \item $(A \cup B) = (B \cup A)$
            \item $(A \cup B \cup C) = (A \cup B) \cup C$
            \item $A \cup A$
            \item $A \subseteq C \land B \subseteq C = A \cup B \subseteq C$
            \item $A \subseteq C \iff A \cup Z = C$
        \end{itemize}
        Con questa operazione ci è possibile generalizzare le coppie non ordinate come segue, dati tre insiemi arbitrari $X_1,X_2,X_3$:
        \begin{center}
            $\{X_1,X_2,X_3\} = \{X_1\} \cup \{X_2\} \cup \{X_3\}$.
        \end{center}
        Ogni insieme può quindi essere rappresentato come l'unione di tutte le sue parti; la stessa cosa vale anche per i numeri naturali che vedremo in seguito.
    \end{definition}
    \item \textbf{Intersezione}\par
    L'intersezione prende solamente gli elementi comuni ad $A$ e $B$.
    \begin{definition}
        \textbf{Intersezione} $A \cap B = \{x|x \in A \land x \in B\}$\par
        Dati due insiemi $A,B$, crea un insieme $C$ che contiene esclusivamente gli elementi comuni ai primi due. Detiene le seguenti proprietà:
        \begin{itemize}
            \item $A \cap \emptyset = \emptyset$
            \item $A \cap B = B \cap A$
            \item $A \cap (B \cap C) = (A \cap C) \cap C$
            \item $A \cap A = A$
            \item $C \subseteq A \land C \subseteq B \implies C \subseteq A \cap B$
            \item $A \subseteq B \iff A \cap B = A$
            \item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
        \end{itemize}
    \end{definition}
    \item \textbf{Prodotto cartesiano}\par
    Il Prodotto Cartesiano è una relazione fra due insiemi dove a partire dagli elementi di $A$, crea tutte le coppie possibili con gli elementi di $B$. Giuro è più semplice a vederlo.

    \begin{definition}
        \textbf{Prodotto Cartesiano} $A \times B = \{(x,y)| x \in A \land y \in B\}$\par
        Dati due insiemi $A,B$, si definisce il loro prodotto cartesiano l'insieme di tutte le coppie ordinate di elementi, indicati da $(a, b)$, tali che il primo elemento a della coppia appartenga all'insieme A e il secondo elemento b della coppia appartenga all'insieme B.
    \end{definition}

    \begin{eg}
        \textbf{Calcolo di un prodotto cartesiano}\par
        Non è molto dissimile da un prodotto di polinomi; moltiplichi ogni elemento di A per ogni elemento di B, come segue:
        \begin{center}
            $A = {1, 2}$, $B = {3, 4}$\par
            $A \times B = C = {(1,3), (1,4), (2,3), (2,4)}$
        \end{center}
    \end{eg}
    \item \textbf{Differenza}\par
    La differenza fra insiemi sottrae gli elementi di $B$ a quelli di $A$.
    \begin{definition}
        \textbf{Differenza} $A \setminus B = \{x|x \in A \land  x \notin B$\}\par
        Dati due insiemi $A,B$, l'operazione differenza sottrae tutti gli elementi di $B$ a quelli di $A$. Nel caso in cui gli insiemi non abbiano elementi in comune, l'operazione non avrà effetto. Detiene le seguenti proprietà:
        \begin{itemize}
            \item $A \setminus \emptyset = A$
            \item $A \setminus A = \emptyset$
            \item $(A \setminus B) \cap B = \emptyset$
            \item $(A \setminus B) \cup A = A$
            \item $A \cup B = (A \setminus B) \cup (A \cap B) \cup (B \setminus A)$
        \end{itemize}
    \end{definition}
    Un'altra operazione molto utile sempre in questo senso è la \textbf{Differenza Simmetrica}, la quale permette di ricavare esclusivamente gli elementi unici da due insiemi.
    \begin{definition}
        \textbf{Differenza Simmetrica} $A \triangle B = (A \setminus B) \cup (B \setminus A)$\par
        Dati due insiemi $A, B$, la differenza simmetrica effettua un'unione fra la differenza $A\setminus B$ e $B\setminus A$, con lo scopo di ottenere Tutti gli elementi appartenenti ai due insiemi che non sono ripetuti. Detiene le seguenti proprietà:
        \begin{itemize}
            \item $A \triangle B = (A \cup B) \setminus (A \cap B)$
            \item $A \triangle B = B \triangle A$
            \item $(A \triangle B) \triangle C = A \triangle (B \triangle C)$
            \item $A \cap (B \triangle C) = (A \cap B) \triangle (A \cap C)$
            \item $A \triangle \emptyset = A$
            \item $A \triangle A = \emptyset$
            \item $(A \triangle B) \cap C = (A \cap C) \triangle (B \cap C)$
        \end{itemize}
    \end{definition}
    \item \textbf{Famiglie di insiemi}\par
    \begin{definition}
        \textbf{Famiglie di insiemi} - $\chi := \{X_i | i \in I\}$\par
        Se ad ogni elemento $i$ di un insieme non vuoto $I$ corrisponde un insieme $X_i, i \to X_i$, allora l'insieme di insiemi $X_i$ è chiamato \textbf{famiglia di insiemi} ed $I$ è il suo insieme di indicizzazione.
    \end{definition}
    INSERISCI ESEMPIO
    \item \textbf{Insieme delle parti}\par
    \begin{definition}
        \textbf{Insieme delle parti} - $P(X) := \{A | A \subseteq X\}$\par
        Definiamo l'insieme delle parti $P(X)$ l'insieme di tutti i sottoinsiemi di $X$. Traiamo inoltre le seguenti conseguenze logiche:
        \begin{itemize}
            \item \textbf{Proprietà}:
            \begin{enumerate}
                \item $A \cup A^c = X$.
                \item $A \cap A^c = \emptyset$.
                \item $(A^c)^c = A$.
                \item $X^c = \emptyset$.
                \item $\emptyset^c = X$.
                \item $A / B = A \cap B^c$
                \item $A \subseteq B \iff B^c \subseteq A^c$.
            \end{enumerate}
            \item \textbf{Proposizioni}:\par
                \begin{enumerate}
                \item $\emptyset \in P(X)$.
                \item $X \in P(X)$.
                \item $A \subseteq X \iff A \in P(X)$.
                \item $x \in X \iff \{x\} \in P(X)$.
            \end{enumerate}
        \end{itemize}
        Definiamo inoltre \textbf{Complemento di un insieme} o insieme complementare $A^c$ di $A$ in $X$ come la il risultato dell'operazione $X / A$; formalmente:
        \begin{center}
            $A^c := X / A := \{x \in X | x \notin A\}$
        \end{center}
    \end{definition}
    \begin{eg}
        \textbf{Insieme delle parti}\par
        Parola chiave "comprende OGNI sottoinsieme ricavabile dall'insieme originale". Osserva e capisci la pattern.
        \begin{itemize}
            \item Se $X = \emptyset \implies P(\emptyset) := \{\emptyset\}$.
            \item Se $X = 1 := \{0\} \implies P(\{0\}) := \{\emptyset,\{0\}\}$.
            \item Se $X = 2 := \{0,1\} \implies P(\{0,1\}) := \{\emptyset, \{0\}, \{1\}, \{0,1\}\}$.
        \end{itemize}
    \end{eg}
\end{itemize}

\subsection{Leggi di De Morgan}
Le leggi di De Morgan sono delle formule importanti per la teoria degli insiemi: consentono di mettere in relazione l'operazione di unione con l'operazione di intersezione. Segue definizione formale:
\begin{definition}
    \textbf{Leggi di De Morgan}:\par
    Siano gli insiemi: $A\subseteq X,B\subseteq X, A^c \subseteq X, B^c\subseteq X$. Valgono le seguenti ipotesi:
    \begin{enumerate}
        \item $(A \cup B)^c = A^c \cap B^c$.
        \item $(A \cap B)^c = A^c \cup B^c$.
    \end{enumerate}
\end{definition}

%

\section{Relazioni fra insiemi}
Ci è possibile mettere in relazione gli elementi di due o più insiemi diversi\footnote{Il totale degli insiemi nella relazione è dato dall'arietà. Se è unaria, sarà per un insieme, se binaria per due e così via.}. Diciamo infatti che se $x\in X$ e $y\in Y$, i due elementi sono in relazione se la loro coppia $(x,y)$ è in una relazione $R$, intesa come sottoinsieme $R$ di $X \times Y$. Segue definizione formale:
\begin{definition}
    \textbf{Corrispondenza}\par
    Una corrispondenza dell'insieme $X$ nell'insieme $Y$ è un qualunque insieme $R \subseteq X \times Y$. Se la coppia $(x,y) \in R$ si dice che $x$ corrisponde a $y$ nella corrispondenza $R$. Si scrive anche\par
    \begin{center}
        $xRy :\iff (x,y) \in R$
    \end{center}
\end{definition}
Lavorando con le corrispondenze possiamo trovare i seguenti casi base:
\begin{itemize}
    \item Un elemento di $X$ può corrispondere a più elementi di $Y$ e viceversa.
    \item Un elemento di $X$ può corrispondere a più elementi di $Y$, i quali a loro volta corrispondono ad altri elementi di $X$.
    \item Relazione vuota, dove in $X$ non ci sono elementi che corrispondono agli elementi di $Y$.
\end{itemize}
A partire da queste nozioni ci è possibile definire i seguenti casi notevoli:
\begin{itemize}
    \item \textbf{Relazione inversa}\par
    \begin{definition}
        \textbf{Relazione inversa} - $R^{-1} \subseteq Y \times X$\par
        La relazione inversa sussiste solamente se abbiamo la certezza che esista la coppia $(x,y) \in R$. La definiamo formalmente come:
        \begin{center}
            $R^{-1} := \{(y,x) \in Y \times X . (y,x) \in R\}$
        \end{center}
        Traiamo inoltre la seguente proprietà:
        \begin{center}
            $f(x)^{-1} = f(x) \land g(x) = g(x)^{-1}$
        \end{center}
    \end{definition}
    \item \textbf{Composizione delle operazioni}\par
    Ti ricorderai il problema delle funzioni composte; è esattamente la stessa cosa: più funzioni messe insieme.
    \begin{definition}
        \textbf{Composizione delle operazioni}\par
        Se $R \subseteq X \times Y \land S \subseteq Y \times Z$, la loro composizione $S \circ R\subseteq X \times Z$ è definita come segue:
        \begin{center}
            $S \circ R := \{(x,z) \in X \times Z . \exists y \in Y . ((x,y) \in R \land (y,z) \in S)\}$
        \end{center}
        E ne traiamo le seguenti conclusioni, date le relazioni $R \subseteq X \times Y$, $S \subseteq Y \times Z$ e $T \subseteq Z \times W$:
        \begin{itemize}
            \item $Diag(Y) \circ R = R$.
            \item $R \circ Diag(X) = R$.
            \item $T \circ (S \circ R) = (T \circ S) \circ R$.
        \end{itemize}
    \end{definition}
    INSERISCI ESEMPIO CON LA DIAGONALE.
\end{itemize}

%

\section{Principi di dimostrazione}
Il processo di dimostrazione matematica è un algoritmo deduttivo utilizzato per provare la verità di ipotesi arbitrarie basandosi sul ragionamento logico. Esistono più metodi per arrivare ad una stessa soluzione:
\begin{itemize}
    \item \textbf{Dimostrazione per assurdo}\par
    Partiamo dal presupposto che la tesi sia falsa. Se si riesce a concludere il processo senza incappare in contraddizioni si è dimostrato che la tesi è falsa, altrimenti è vera.\par
    \begin{eg}
        \textbf{Dimostrazione per assurdo}\par
        INSERISCI ESEMPIO.
    \end{eg}
    \item \textbf{Dimostrazione per induzione}\par
    Algoritmo basato sul passaggio dallo specifico al generale, si compone di due passi:
    \begin{enumerate}
        \item Passo base, dove si prende un valore comodo per provare la veridicità della tesi nel caso più facile.
        \item Passo induttivo, dove si prova, basandosi sul caso base, che valga anche per tutte le istanze successive.
    \end{enumerate}
    \begin{eg}
        \textbf{Dimostrazione per induzione su $\mathbb{N}$}\par
        INSERISCI ESEMPIO
    \end{eg}
    \begin{eg}
        \textbf{Dimostrazione per induzione su $\mathbb{N}^*$}\par
        Definiamo l'insieme numerico di lavoro come $\mathbb{N}^* = \mathbb{N} \setminus \{0\} = \{1, 2, ..., n\}$\par
        Tesi da provare: $\theta(n) = \forall n \in \mathbb{N}^*.(1+2+...+n=\dfrac{n(n+1)}{2})$
        \begin{itemize}
            \item \textbf{Passo base}:\par
            Testiamo se la tesi vale sostituendo $n$ a $1$\par
            \begin{center}
                $\theta(1) \iff 1 = \dfrac{1(1+1)}{2} = 1$, che è vera.
            \end{center}
            \item \textbf{Passo induttivo}:\par
            Espandiamo il ragionamento per $\theta(n+1)$. Va sostituito $(n+1)$ alla singola $n$ presente nella tesi iniziale.
            \begin{center}
                $\theta(n+1) \iff (1+2+...+n+(n+1)) = \dfrac{(n+1)((n+1)+1)}{2} = \dfrac{(n+1)(n+2)}{2}$
            \end{center}
            Adesso proviamo che il risultato ottenuto è valido:
            \begin{center}
                $\dfrac{n(n+1)}{2}+(n+1) = \dfrac{n(n+1) + 2(n+1)}{2} = \dfrac{n^2+3n+2}{2} = \dfrac{(n+1)(n+2)}{2}$
            \end{center}
        \end{itemize}
        Come volevasi dimostrare.
    \end{eg}
    \item \textbf{Dimostrazione per ricorsione}\par
    La ricorsione si costituisce anch'essa di due casi, ovvero il caso base, da dove inizia tutto, ed il caso ricorsivo, che avanza tenendo conto dei valori precedentemente ottenuti.
    \begin{eg}
        \textbf{Dimostrazione per ricorsione}\par
        Definiamo la funzione $n!$:
        \begin{itemize}
            \item Passo base\par
            Se $n = 0 \implies 1$
            \item Passo ricorsivo\par
            Se $n > 0 \implies (n-1)! \times n$ 
        \end{itemize}
        Proviamo a ragionare come si comporta tale funzione quando sostituiamo alla $n$ i valori presi in esame. Otterremo che:
        \begin{center}
            $0! = (0-1)! \times1 = 1$\par
            $1! = (1-1)!\times1 = 1\times1 = 1$\par
            $2! = (2-1)!\times2 = 1\times2 = 2$\par
            $3! = (3-2)!\times3 = 2\times3 = 6$\par
            $4! = (4-3)!\times4 = 6\times4 = 24$\par
        \end{center}
    \end{eg}
\end{itemize}

\section{Domande di teoria}

\begin{theorem}
    Here goes a theorem.
\end{theorem}

\begin{proof}
        Here goes the proof
\end{proof}

\begin{corollary}
    Here goes a collorary
\end{corollary}

\begin{eg}
    Here goes an example
\end{eg}

\begin{note}
    Here goes a note 
\end{note}

\begin{lemma}
    Here goes a lemma
\end{lemma}

\begin{prop}
    Here goes a proposition
\end{prop}

\begin{definition}
    Here goes a definition 
\end{definition}

\subsection{Esercizi}