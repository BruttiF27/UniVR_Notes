\section{Tipi di memorie RAM - Random Access Memory}
Tempo di conoscere il funzionamento di ciò che non si ha mai abbastanza: la \textbf{Random Access Memory}. Si dice ad accesso casuale perché il tempo di accesso ai registri è indipendente dalla distanza percorsa dai segnali. Immaginala; è composta da varie celle di bits organizzate e distanziate opportunamente entro un certo numero di bit, rendendole \textit{indirizzabili}\footnote{Per accedere alla memoria è necessario sapere dove essa si trova, quindi conoscere il suo indirizzo.}; queste sono collegate orizzontalmente dalle \textbf{Word Lines} e verticalmente dalle \textbf{Bit Lines}, le quali sono collegate ad un circuito apposito per effettuare operazioni di lettura e scrittura.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{Images/OrganizzazioneMemoria.png}
    \caption{Organizzazione della memoria}
    \label{fig:enter-label}
\end{figure}

Diciamo per esempio di avere $2^4$ indirizzi, quindi quattro entrate nel decoder e sedici uscite, ovvero le Word Lines. Noi vogliamo poter attivare una singola cella fra tutte quelle presenti in memoria.\par\quad
La Linea di Parola andrà a scegliere la cella corretta, la quale invierà un segnale ai circuiti R/W che produrranno in output il bit di interesse\footnote{Questo segnale è di forma booleana, dove 0 significa scrittura, 1 lettura}.\par\quad
Una caratteristica aggiuntiva del modello visionabile nella figura 5.1 è la presenza di un'ulteriore Bit Line apposita per la S-RAM, che vedremo meglio fra poco; ha lo scopo di amplificare la differenza nel segnale output di R/W\footnote{Si effettua una sottrazione. Se il circuito legge $1 - 0 < 0$, out = 1; altrimenti se $1 - 0 > 0$, out = 0}. Questo circuito è connesso direttamente alla scheda madre tramite pins dorati, il cui numero dipende dai seguenti tre tipi di segnale:
\begin{itemize}
    \item \textit{Di indirizzo}; Dipendono da quanta memoria è possibile indirizzare.
    \item \textit{Di dato}; Dipendono dall'indirizzabilità.
    \item \textit{Di controllo}; Fanno parte dei circuiti R/W e si chiamano \textbf{controlSignal} e \textbf{chipSelect}
\end{itemize}
Per esempio, se avessimo 4 indirizzi, 8 segnali di dato, 1 segnale di R/W ed 1 segnale di chipSelect avremmo un totale di 14 segnali, di conseguenza quattordici pins.
Orsù, non indugiamo e andiamo a studiare nel dettaglio i vari tipi di memoria.

%

\subsection{Static RAM}
La memoria ad accesso casuale statica, \textbf{S-RAM}, è di tipo \textit{volatile}\footnote{Capace di mantenere il dato solamente se alimentata dall'elettricità.} ed è composta da due semiconduttori di tecnologia CMOS. Sono presenti nel circuito i segnali \textit{bit vero} e \textit{bit falso}, che per comodità chiamerò b e !b; i quali vengono inviati tramite le apposite linee.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Images/SRAM.png}
    \caption{Modello di Static RAM}
    \label{fig:enter-label}
\end{figure}

L'operazione da compiere è selezionata tramite due transistors. Nel caso in cui la Word Line abbia il valore 0, b e !b saranno isolati; se invece ha il valore 1, x otterrà il segnale b e y !b.\par\quad
Per quanto veloce questa operazione possa essere, richiede un costo energetico importante, per questo che sono usate in quantità ridotte e posizionate puramente nella CPU. Vediamo ora un esempio del funzionamento della S-RAM, un probabile esercizio da esame:\newline

Ci è assegnata una matrice 32x32 in bits, per un totale di 1024 bits. Noi vogliamo avere 10b di indirizzo ed 1b di dato.\par\quad
Una prima cosa che possiamo dedurre sono le entrate del decoder; siccome la matrice riceve 32 segnali equivalenti a $2^5$b, avremo 5 entrate. Questo gruppo consente di puntare ad una riga, ma è necessario trovare un metodo per selezionare la cella precisa.\par\quad
Per far ciò si utilizza un blocco di logica di multiplexing il quale riceve il segnale di R/W e, date le altre 32 entrate, avrà un segnale di controllo a 5b, ovvero quelli rimanenti di indirizzo. Il blocco darà in output il bit preciso che è stato selezionato.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\linewidth]{Images/funzSRAM.png}
    \caption{Funzionamento della S-RAM}
    \label{fig:enter-label}
\end{figure}

%

\subsection{Dynamic RAM}
Nella memoria ad accesso casuale dinamica non è possibile memorizzare indefinitamente il contenuto di una cella poiché la memoria effettua un \textit{refresh} periodico che libera lo spazio, indipendentemente dal fatto che una cella sia piena o meno. Dispone di un \textit{condensatore}, un accumulatore di carica elettrica costante rispetto alla propria capacità; al suo interno si trova dell'isolante elettrico, il quale rilascia il segnale ad ogni refresh.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\linewidth]{Images/DRAM.png}
    \caption{Modello di Dynamic RAM}
    \label{fig:enter-label}
\end{figure}

La D-RAM risulta più lenta della S-RAM perché si scarica anche se isolata e di conseguenza in caso di necessità deve essere nuovamente riempita, specie perché è nostra intenzione preservare il contenuto il più possibile. Anche la sola operazione di lettura è distruttiva, perché se si vuole accedere al contenuto è necessario liberarlo. 
Essendo poi una memoria più compatta e capiente, è molto probabile interfacciarsi con dimensioni di bit molto grandi con di conseguenza molti più segnali. Vediamo un esempio del funzionamento:\newline

Diciamo che un refresh avviene ogni 64ms, il tempo minimo per accedere ad una riga è 5ms e tutte le righe saranno refreshate ogni 8192 cicli di rinfresco. Possiamo ricavare i \textit{millisecondi necessari per effettuare un refresh} con $8192\times0,05 = 0,41ms$ ed il \textit{costo del refresh} con $\frac{0,41}{64} = 0,0064ms$.\par\quad
La nostra matrice questa volta ha $16384 = 2^{14}$ righe per $2048 = 2^{11}$ bytes; avremo 14b in entrata nel decoder e 11b di selezione nella logica di multiplexing. I bits dell'indirizzo totali saranno $14 + 11 = 25$ ed i pins da utilizzare saranno la somma fra tutti i segnali: $25 + 8 + 2 = 35$. Il fatto è che questi ultimi sono tanti e richiederebbero costi importanti, ragion per cui è stata ideata la tecnica di \textbf{strobing} dell'indirizzo, un piccolo sacrificio della velocità per consentire un risparmio in oro.\par\quad
Sostanzialmente si inviano le due parti dei bits di indirizzo in istanze diverse; questa strategia è resa possibile grazie a due registri che consentono il passaggio dei dati solo in presenza del proprio segnale, chiamato \textbf{RAS}\footnote{Row Address Strobe} per le righe e \textbf{CAS}\footnote{Column Address Strobe} per le colonne.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{Images/funzDRAM.png}
    \caption{Funzionamento della D-RAM}
    \label{fig:enter-label}
\end{figure}

Esistono inoltre le \textbf{SD-RAM}\footnote{Synchronous Dynamic RAM - RAM Dinamiche Sincrone}, le quali svolgono la medesima funzione ma sono governate da un clock. La particolarità di questa memoria è la sua capacità di velocizzare i processi in caso di accessi consecutivi; ciò sinergizza con il \textit{Principio di Località}, il quale vedremo meglio in seguito nella gerearchia di memoria, ed è per questo che le SD-RAM vengono posizionate nella CPU, risparmiando anche sul costo dei pins.

%

\subsection{Banchi di memoria}
Un ultimo modello molto importante è rappresentato dai \textbf{Banchi di memoria}; insiemi integrati di memoria collegati fra loro per condividere Bit Line e Word Line. Ci si può trovare in una situazione dove risulta comodo modificare a piacimento bits ed indirizzi e questo modello si presta particolarmente bene.\par\quad
L'architettura presenta i soliti bits di indirizzo per selezionare la riga e quelli inviati al decoder per effettuare il chipSelect e selezionare la cella esatta. Eseguita la loro istruzione, comunicheranno quanto elaborato mediante un BUS apposito che collega tutte le celle di una colonna. Vediamo ora un esempio pratico:\newline

Diciamo di avere componenti da 512K indirizzi a 8b, ma per nostra comodità vogliamo creare un banco di memoria a 32b per 2M indirizzi. Come fare?\par\quad
Iniziamo col capire di quante celle abbiamo bisogno per ogni riga; sappiamo che $8 \times 4 = 32$, quindi serviranno quattro celle da 512K per 8b, e questa è già una parte. Noi però necessitiamo di 2M indirizzi.\par\quad
Se ricordi le grandezze in dati, sai che $1M = 1024K$ e che quindi $2M = 2048K$. Avremo bisogno di quattro righe totali.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{Images/BancoDiMemoria.png}
    \caption{Banco Di Memoria}
    \label{fig:enter-label}
\end{figure}

%

\section{Caratteristiche delle memorie e relativa gerarchia}
Andiamo ora ad osservare ulteriori tipologie di memoria insieme alle loro caratteristiche. Oltre a registri, cache e RAM, abbiamo:\newline

\textbf{- Solid State Disk}\newline
Questo tipo di memoria è quello utilizzato oggigiorno in qualunque computer o console per garantire la massima velocità in relazione alla propria struttura. Appartiene all'insieme delle memorie \textit{flash}, usate anche per la creazione di schede SIM e chiavette USB, che agiscono come estensioni del BUS, dal quale ovviamente ricevono i dati.\par\quad
Sono divise in blocchi capaci di contenere un determinato numero di parole e le informazioni sono scritte in modo circolare; vediamolo nel dettaglio:\par\quad
Il blocco con le informazioni viene interamente copiato in un \textit{buffer} che scriverà i dati sulla RAM, la quale invierà tutto ai blocchi della memoria flash. Quando uno finisce lo spazio, si passa al successivo.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\linewidth]{Images/FlashMemory.png}
    \caption{Memoria Flash}
    \label{fig:enter-label}
\end{figure}

Questo processo è reso possibile dai \textbf{droganti}; elementi che muovendosi nella memoria sono capaci di modificare la struttura interna del silicio. Dove questo però consente la scrittura, fa sorgere un nuovo problema: l'\textbf{isteresi}.\par\quad
Per effettuare modifiche al materiale è necessario rimuoverne dei pezzi, poco a poco; questo significa che più questa cosa avviene, più la memoria risulterà inaffidabile, fino ad arrivare ad un punto dove sarà inutilizzabile. Dal primo utilizzo, se il dispositivo non è difettoso, vedrà la sua probabilità di rottura diminuire fino ad arrivare al punto \textbf{MTBF}\footnote{Mean Time Between Failure - Tempo medio fra fallimenti}, dove da lì in poi aumenta esponenzialmente.\par\quad
Abbiamo inoltre a disposizione nel nostro arsenale una legge particolarmente utile per i nostri scopi di ottimizzazione hardware: Il principio di località, ramificato nei seguenti due concetti:
\begin{itemize}
    \item \textit{Località spaziale}; Quando una cella di memoria è utilizzata è altamente probabile che vengano usate anche quelle ad essa vicine.
    \item \textit{Località temporale}; Quando una cella di memoria è utilizzata è altamente probabile che venga usata nuovamente di lì a poco.
\end{itemize}


\textbf{- Hard Disk}\newline
Questo è un tipo di memoria molto importante, che sta venendo tuttavia sostituito col tempo a causa di alcune sue caratteristiche negative; come sono fatti?\par\quad
L'architettura presenta un albero che ruota ad una certa velocità costante e sposta allo stesso tempo un piatto dalla superficie magnetica composta da tanti piccoli magnetini separati in diverse aree, magnetizzati in modo diverso e posizionati in tal modo da consentire la manipolazione di dati. Gli Hard disks sono poi divisi in tracce che comunicano i loro rispettivi punti di inizio e di fine. Queste sono a loro volta separate in blocchi equamente distanziati.\par\quad
Questa era la loro struttura, ma come funzionano?
Le operazioni di lettura e scrittura avvengono mediante forze magnetiche. Sopra il piatto è presente un braccio con una spira che, se elettrificata, ha la capacità di emettere un campo magnetico. Nel caso della lettura passa solamente sopra ai magnetini coi dati desiderati, mentre per la scrittura è necessario il suo campo magnetico poiché è necessario cambiare l'orientamento dei magnetini toccati.\par\quad

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\linewidth]{Images/HardDisk.png}
    \caption{Architettura di un Hard Disk}
    \label{fig:enter-label}
\end{figure}

La spira non deve per nessuna ragione toccare il disco perché è stata creata per stare a debita distanza. Se questa dovesse restringersi o allontanarsi non sarebbe più possibile effettuare le operazioni di lettura e scrittura e quindi usare i dati contenuti nella memoria.\par\quad
Prima di un'operazione, tuttavia, agisce un buffer il cui tempo di lavoro totale è dato dalla seguente equazione: $T_{Totale} = T_{RicercaMagnete} + T_{Rotazione} + T_{LetturaBlocco}$. Una volta terminato il suo lavoro sarà possibile effettuare l'operazione richiesta. Bisogna infine farsi domande sull'algoritmo per l'organizzazione dei files.\par\quad
Partiamo dal presupposto che i files sono composti da una catena di blocchi; la \textbf{FAT}\footnote{File Allocation Table - Tabella di Allocazione dei File.} propria del sistema operativo riceve in input il nome del file ed userà un puntatore per spostarsi sulla catena che costituisce il primo allo scopo di leggerla tutta; finita questa operazione verrà tutto scritto sul disco nella catena dei blocchi liberi. Invece nel caso in cui si cancellassero dei files, i loro blocchi verranno inseriti nella suddetta catena per poter essere eventualmente sovrascritti. Fai attenzione a ciò che salvi, poiché la sovrascrittura non implica la completa cancellazione delle modifiche fisiche della memoria.\newline

\textbf{- Compact Disk e Digital Versatile Disk}\newline
La nostra penultima memoria da studiare è il supporto ottico. Come funzionano?\par\quad
I CD sono unità di memoria nate per il salvataggio di brani musicali i cui dati sono salvati sotto forma di codice binario in una singola traccia a spirale. 
Le informazioni vengono lette da un laser che viene riflettuto in un apposito lettore. Per direzionare il raggio viene utilizzato uno specchietto che rende possibile coprire ogni zona del disco ottico. Allo scopo di effettuare l'operazione di scrittura, invece, si utilizza un laser più potente in grado di creare buchi nel disco, i quali verranno eventualmente letti tramite il laser normale.\par\quad
Sorse poi la domanda: "Come migliorare ulteriormente questa tecnologia per salvare ancora più dati?"; la soluzione si rivelò in gel e luci per il laser di colori diversi. I dischi sono cosparsi del suddetto materiale e si scrive su di essi con luce blu, con frequenza maggiore, e rossa, con frequenza minore. Lasciando il colore nello strato in modalità diverse, il laser a luce bianca potrà leggere quanto scritto e distinguere fra le due scritture. Con questa idea nacquero i \textbf{DVD-ROM}\footnote{DVD Read Only Memory - DVD sola lettura} ed i \textbf{DVD-RW}\footnote{DVD Rewritable - DVD Riscrivibile}.

\textbf{- Digital Audio Tape}\newline
Tecnologia di vita breve partorita da Sony. Raramente sono ancora utilizzati per effettuare dei backup nonostante il loro funzionamento fastidiosamente \textit{sequenziale} per le operazioni di lettura e scrittura. Facciamo direttamente un esempio; mettiamo caso di avere un nastro scritto al 95\% e riteniamo necessario leggere o scrivere in una posizione precedente. Qui sarà necessario riavvolgere tutta la memoria fino al punto desiderato. Non è molto efficiente.\newline

Lascio ora una tabella riassuntiva di quanto visto, aggiungendo ulteriori caratteristiche.
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        Memoria & Tecnologia & Accesso & Velocità [s] & Dimensioni [B] & Costo [$\frac{€}{B}$]\\
        \hline
        Registri & CMOS, elett., volatile & Datapath & $10^{-9}$ & $10^4$ & $10^{-3}$\\
        \hline
        Cache & Statica, elett., volatile & Associativo & $10^{-8}$ & $10^7$ & $10^{-6}$\\
        \hline
        RAM & Dinam., elett., volatile & Casuale & $10^{-7}$ & $10^{10}$ & $10^{-8}$\\
        \hline
        SSD & Elett., flash, non vol. & A blocchi & $10^{-5}$ & $10^{12}$ & $10^{-10}$\\
        \hline
        HD & Magn., mecc., non vol. & Diretto & $10^{-3}$ & $10^{13}$ & $10^{-11}$\\
        \hline
        CD - DVD & Ottica & Diretto & $10^{-3}$ & $10^{10}$ o $10^{13}$ & $10^{-9}$\\
        \hline
        DAT & Magnetica & Sequenziale & $10^0$ & $10^9$ o $10^{11}$ & $10^{-9}$\\
        \hline
    \end{tabular}
    \caption{Memorie a confronto ordinate in base alla velocità}
    \label{tab:my_label}
\end{table}

%

\section{Memoria Cache}
Parliamo ora della \textbf{Memoria Cache}, dalla velocità assurda. Nella gerarchia di memoria è seconda solamente ai registri, si trova nella CPU e se le informazioni sono in essa presenti, hai la garanzia che si eseguano in un solo ciclo di clock, ottenendo il tuo tanto bramato 1CPI.\par\quad
Da grandi velocità derivano grandi responsabilità ed è per questo che nella cache stanno dati ed istruzioni importanti se non fondamentali. Sappiamo che la cache è meno capiente della memoria RAM, creando i concetti di:
\begin{itemize}
    \item Cache Hit; L'informazione è presente in cache e viene elaborata in 1CPI.
    \item Cache Miss; L'informazione non è presente in cache e la pagina deve essere recuperata dalla RAM e messa nella prima memoria. Alla CPU saranno fornite le parole.
\end{itemize}
Una cosa che bisogna tenere a mente è la dimensione della singola parola: 1Byte = 8bit, dalla quale è possibile ottenere la dimensione in bit degli indirizzi di memoria. Diciamo di avere 4GB di RAM, dovrai usare la seguente formula: $\frac{4GB}{1B} = 4G$, ovvero 4GigaParole.\par\quad
Nella definizione delle pagine è possibile decidere la grandezza, caldamente consigliata essere una potenza del 2. Diciamo che una pagina ha il valore di 4KB. Dividila per la dimensione della RAM e della cache per ottenere quante pagine possono essere contenute nelle due memorie. La formula è simile a quella di prima: $\frac{4GB}{4KB} = 1M$ in RAM, $\frac{4MB}{4KB} = 1K$ in cache.\par\quad
Quanti bits mi serviranno per indirizzare una pagina? $4\times2^{10} = 2^{12}$. La risposta è 12. Temo sia ora di imparare le misure in bit, se così tu non abbia già fatto.\par\quad
Le pagine presenti nella cache si copiano mediante un indirizzamento dalla stessa e possiamo vedere il suo indirizzo come se fosse diviso in bit. In questo caso parliamo di 22bits totali, dove 12 servono, come visto poco fa, per indirizzare la pagina, mentre i restanti 10 per la parola.\par\quad
Di indirizzamenti ne esistono di tre tipi: diretto, associativo e set-associativo, il più usato. Approfondiamoli uno per volta.\newline

\textbf{- Indirizzamento diretto}\footnote{Vedi figura in merito; equivale ad un singolo indirizzamento set-associativo}\quad$\frac{N. Pagine RAM}{N. Pagine Cache} = x[b]$\newline
In questo metodo abbiamo che ogni singola pagina della RAM ha una sola posizione in cui andare nelle pagine cache. Noi vogliamo sapere in che parte della cache il segnale va a finire.\par\quad
Qui si rende necessario dividere i 32bits della RAM in tre parti: 10bits per indirizzare la parola, 12bits per indirizzare la pagina e gli ultimi 10bits per l'etichetta della pagina.\par\quad
Riceviamo i bits dal MAR per poi metterli nella RAM, dopodiché, si effettuerà un check nel vettore sovramenzionato. Se la pagina corrisponde a quella ottenuta dalla RAM avremo un cache hit, metteremo insieme bits di pagina coi bits di parola e accederemo alla cache. Se la pagina è diversa avremo un cache miss ed il microprocessore andrà in RAM per prendere la pagina richiesta e sostituire quella precedente.\newline

\textbf{- Indirizzamento associativo}\footnote{Corrisponde ad 1set-associativo, quindi come se tutte le etichette fossero un unico set.}\newline
Con questo indirizzamento non abbiamo il lusso di sapere dove va una data pagina, perché verranno controllate tutte fin quando non si troverà quella corrispondente (immaginati i cache miss se ti serve l'ultima pagina). Vengono tenuti i 10bits per la parola, ma i restanti 22bits saranno usati per l'etichetta. Una volta trovata, si darà l'indirizzo in cache.\newline

\textbf{- Indirizzamento set-associativo}\quad $\frac{N.PagineCache}{N.PagineInSet} = totSets$\newline
Questo metodo è una sinergia fra i due appena visti. Fondamentalmente ci è possibile raggruppare delle pagine in degli insiemi, sets, per poter effettuare il controllo delle etichette direttamente in tal gruppo. Nella divisione dei bits dell'indirizzo in RAM, oltre ai 10bits per la parola, al posto della pagina, avremo, dipendentemente da quanti insiemi sono presenti in memoria, un numero $n$bits per i sets ed i rimanenti verranno usati per l'etichetta.\newline

Tutto molto bello ma c'è un ultimo problema: mettiamo caso di avere un cache miss e di non avere più spazio in tal memoria. Bisogna trovare tale \textbf{algoritmo di sostituzione} per scaricare delle pagine ed inserire quelle richieste. Ne esistono due e riguardano rispettivamente lo scarico della pagina più vecchia, \textbf{LRU}, Least Recently Used, o la più recente, \textbf{MRU}, Most Recently Used, e funzionano grazie alla presenza di un contatore in ogni pagina che aumenta ad ogni ciclo di clock. La comodità dell'algoritmo dipende dallo scopo della macchina.

\begin{figure}[b]
    \centering
    \includegraphics[width=0.5\linewidth]{Images/ramToCache.png}
    \caption{Comunicazione fra RAM e cache}
    \label{fig:enter-label}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{Images/DivInBit.png}
    \caption{Divisione in bit per i metodi di indirizzamento}
    \label{fig:enter-label}
\end{figure}

%

\section{Memoria Virtuale}
Iniziamo ora un ulteriore approfondimento sulla memoria presentando due processi utili per i nostri scopi:
\begin{itemize}
    \item Rilocazione; Strategia che permette di usare la stessa RAM senza sovrascrivere i registri
    \item Paginazione; Strategia che permette a più processi di utilizzare efficientemente la stessa RAM
\end{itemize}
Questi due processi ci consentono di dare l'impressione al sistema operativo di avere a disposizione tutta la ram dell'architettura, ovvero di \textbf{virtualizzare la memoria}.\par
\quad Partiamo da un semplice presupposto; le varie istruzioni dei codici devono avere un indirizzo per poter andare nelle zone di memoria della Stack, Heap etc. e questo viene loro assegnato in ordine crescente dall'assemblatore o dal compilatore, dipendentemente dal linguaggio nel quale si sta scrivendo.\par
\quad Le parole verranno inserite nello spazio di memoria appositamente creato per il programma, quindi avremo una parola in $i_1$, un'altra in $i_2$ e così via fino all'indirizzo massimo. Tuttavia al momento non sai dove questo intervallo di indirizzi verrà posizionato.\par
\quad Qui entra in gioco la \textbf{Rilocazione}; trasforma gli indirizzi logici in indirizzi fisici, i quali verranno caricati sul BUS indirizzi. Si tratta di un processo necessario in quanto per poter accedere ai dati serve l'indirizzo fisico. Abbiamo due modi per effettuare la rilocazione: statica e dinamica.\newline

\textbf{- Rilocazione statica}\par
Questa strategia è usata puramente per i sistemi la cui struttura è statica, quindi per i sistemi embedded.\par \quad Diciamo che un programma deve partire dall'indirizzo 1438; a questo numero saranno sommati tutti gli indirizzi logici dei dati del codice, così da non sovrascrivere i registri precedenti. Eventualmente, se sono presenti delle condizioni if o cicli, il codice si biforcherà dipendentemente dalla loro quantità. Se non fosse per il compilatore o l'assemblatore, in quanto sono loro a trovare e segnare le parti dei bits che rappresentano l'indirizzo, questo algoritmo non avrebbe mai visto la luce.\newline

\textbf{- Rilocazione dinamica}\par
Questa è la strategia utilizzata nei sistemi programmabili, quindi quella di nostro maggiore interesse.\par
\quad Serve a ottenere un indirizzo fisico da uno logico ed entrare nel MAR. Per fare ciò abbiamo due registri \textit{base} e \textit{limit} che contengono rispettivamente la prima e l'ultima zona di memoria creata per il programma. Questi lavorano insieme ad un circuito di \textit{testing} che controlla se la somma fra indirizzo logico e base è compresa nella zona di memoria apposita. Se lo è, crea l'indirizzo fisico e lo invia al MAR, altrimenti si ha un errore di Segmentation Fault.\newline

C'è tuttavia un problema in questi metodi. Immagina di voler caricare tre diversi programmi: $P_1$, $P_2$, $P_3$, i quali verranno posizionati in ordine nelle rispettive zone di memoria.\par\quad
Diciamo che $P_1$ richiede una malloc, ma non è possibile donare altro spazio poiché è coperto da $P_2$ e non è possibile spostare i processi, oppure mettiamo caso che $P_2$ finisca il suo lavoro e devi inserire $P_4$ ma non ha abbastanza spazio.

Come puoi vedere, è un bordello. Ragion per cui hanno ideato la \textbf{Paginazione}; l'assegnazione ad ogni processo di un numero $n$ di pagine indipendentemente dalla loro posizione fisica. Ciò risolve il problema alla radice perché potrei aggiungere pagine quando richieste.\par\quad
Ma come funziona? Abbiamo la solita divisione dei 32bits nella memoria, dove 10 rappresentano la parola e i restanti 22 l'indirizzo logico che poi verrà calcolato nell'indirizzo fisico. Noi potremmo assegnare a questi bit di indirizzo una pagina logica e una fisica, mantenendo lo stesso procedimento visto nello scorso capitolo. Il twist è la presenza della \textbf{Tabella delle pagine}; una matrice tanto grande quanto le pagine del processo, dove sono scritte in ordine crescente tutte le pagine logiche insieme alla loro rispettiva pagina fisica.\par\quad
Questa matrice è contenuta in un circuito chiamato \textbf{MMU}; Memory Management Unit, presente nella CPU e guidato dal sistema operativo. Riceve i dati dalla tabella con la possibilità di ampliarla quando richiesto. Può inoltre riconoscere se le informazioni ricevute sono utili o meno, ed eventualmente scartare le seconde.\newline

Questo circuito è necessario per due motivi:
\begin{enumerate}
    \item Se questo compito di ricerca fosse effettuato dal sistema operativo, si richiederebbe moltissimo tempo.
    \item Sinergizza con il principio di località, rendendo il processo efficiente.
\end{enumerate}

Una curiosa domanda ora: quanto è grande la tabella delle pagine? Comprenderà certamente l'insieme delle pagine necessarie per il funzionamento del programma. Chiamiamo tale famiglia il \textbf{Working Set}, basato sul principio di località.\par\quad
Capirai che ogni processo avrà il proprio working set, ma una cosa meno ovvia è come si tratta del giusto equilibrio fra tempo di esecuzione ed il numero di pagine minimo utilizzabile, allo scopo di garantire le prestazioni migliori.\newline

Rimane solo da vedere il gran sotterfugio: la \textbf{Memoria Virtuale}. Per capirla iniziamo a ragionare dal working set. Come precedentemente menzionato, ogni processo ha il suo working set che lavora indipendentemente dagli altri e noi dobbiamo convincere il sistema operativo che è in grado di usare tutta la memoria fisica.\par\quad Posso prendere un pezzo di SSD (o HD, che dir si voglia) detto \textbf{Swap} e donarlo al sistema operativo. Se una pagina del set viene usata poco, (controllo eseguito mediante contatori nella tabella delle pagine incrementati ad ogni ciclo di clock) verrà spostata in questo swap per liberare spazio in RAM. Chiariamo che questo processo non butta via le pagine perché sempre nella tabella è presente un'area apposita che dice se una pagina si trova o meno nello swap.\par\quad Nel caso in cui serva una pagina presente nello swap, la si scambierà sempre la pagina più vecchia in ram. Questo algoritmo non è tuttavia onnipotente, perché dando troppo spazio allo swap potresti inchiodare il sistema. Caution is advised.\newpage

\begin{figure}
    \centering
    \begin{minipage}{.4\textwidth}
        \centering
        \includegraphics[width=.8\linewidth]{Images/Relocation.drawio.png}
        \captionof{figure}{Circuito per la rilocazione}
        \label{fig:test1}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{Images/wSet graph.drawio.png}
        \captionof{figure}{Come ottenere il working set}
        \label{fig:test2}
    \end{minipage}
\end{figure}

\begin{figure}
            \includegraphics[width=1\linewidth]{Images/wordToPage.png}
            \captionof{figure}{Percorso di paginazione}
            \label{fig:test3}
\end{figure}

%

\section{Pipelining}
Finora abbiamo considerato la processione dei dati come una FSM a quattro stati, ma è possibile per i nostri scopi dividere l'ultimo stato di execution fra \textit{esecuzione istruzione} e \textit{salvataggio risultato} e chiameremo quest'ultimo stato \textbf{WriteBack}.\newline

Immaginiamo di avere un circuito semplice, dal leggero costo in runtime: un sommatore. Ti guiderò in ogni istruzione così fai anche un ripasso.\par\quad
Nello stato fetch riceviamo le istruzioni dai registri o dalla memoria del calcolatore. Abbiamo un'architettura ottimizzata con un circuito di somma esterno e registri flip-flop; di conseguenza avremo un accesso alla memoria in un ciclo di clock.\par\quad
La fase di decode ha il compito di decodificare le istruzioni mediante le informazioni che riceve da registri o memoria. Queste possono richiedere un accesso a memoria o meno. Dipendentemente da quanti sono avremo il nostro ciclo di memoria in un ciclo di clock.\par\quad
Siamo arrivati all'esecuzione. Non richiede accessi a memoria e nell'immaginario di un'architettura ottimizzata con ben tre bus per la ALU, si riesce ad effettuare il tutto in un ciclo di clock.\par\quad
L'ultima fase di WriteBack richiede un accesso in memoria solamente quando deve salvare i dati, facendo un accesso a memoria. Se non accede, nulla è modificato. Serve in ogni caso un ciclo di clock.\newline

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
         & Ciclo di Memoria & Ciclo di clock\\
        \hline
        Fetch & 1 & 1\\
        \hline
        Decode & da 0 a 1 & 1\\
        \hline
        Execution & 0 & 1\\
        \hline
        WriteBack & da 0 a 1 & 1\\
        \hline
        Totale & da 1 a 2 & 4\\
        \hline
    \end{tabular}
    \caption{Costo in accessi a memoria/cicli di clock dei quattro stati}
    \label{Tabella}
\end{table}
Puoi osservare nella tabella riassuntiva che il numero minimo di cicli ottenibile è $1 + 4 = 5$, 6 nel peggiore dei casi. Questo è ottenibile solamente con un ISA richiedente un solo accesso a memoria, ma ahimè, non è neanche lontanamente vicino al nostro amato 1CPI.\par\quad
Possiamo ulteriormente ottimizzare minimizzare la memoria scegliendo quale operazione fra decode e writeBack avrà il diritto di accedervi.\footnote{Non possono avere entrambe accesso alla memoria, devi per forza sceglierne una.} Conviene inoltre dividere i bits della memoria cache in due parti: una per i dati e l'altra per le istruzioni, rendendo possibile farle lavorare in contemporanea a due mansioni diverse.\newline

Non è ancora abbastanza; per questo introduciamo la strategia di \textbf{pipeline}; una strategia portentosa che vede i quattro stati messi in fila come una catena di montaggio. Questi sono separati da dei banchi di registri che salveranno quanto svolto per darlo allo stato seguente.\par\quad
Questo sistema consente alle quattro istruzioni di lavorare indipendentemente l'una dall'altra\footnote{Nella maggior parte dei casi è così. L'eccezione è quando si hanno cicli e condizioni.}, riducendo drasticamente i cicli di clock necessari per elaborare un programma. Osserviamo l'idea per il suo funzionamento:
\begin{enumerate}
    \item L'istruzione di \textit{fetch} prende dai registri il valore del PC e dalla cache istruzioni il compito che dovrà eseguire. Incrementerà di uno il PC e passerà nel banco il valore di quest'ultimo insieme a quello dell'IR.
    \item L'istruzione di \textit{decode} riceve le informazioni dal banco precedente e dipendentemente dalla modalità di indirizzamento, prenderà il codice dalla cache o dai registri. Metterà infine nel suo banco gli operandi ed il valore di PSW.
    \item L'istruzione di \textit{execution} riceverà gli operandi e ne calcolerà il risultato. Aggiornerà infine i registri e metterà il tutto nel suo banco insieme al PSW aggiornato.
    \item L'istruzione \textit{WriteBack} infine salverà questi risultati nella cache dati o nei registri, dipendentemente da dove è richiesto.
\end{enumerate}

E questa era la teoria; passando alla pratica si presentano due problemi:
\begin{itemize}
    \item Abbiamo una situazione dove ogni stato sarà molto più complesso, siccome le quattro operazioni agiscono indipendentemente e nello stesso ciclo di clock.
    \item Le \textit{bolle}; delle istruzioni che non possono essere eseguite nello stesso ciclo di clock a causa di una dipendenza condizionale o ciclica.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{Images/pipeline.drawio.png}
    \caption{Circuito di pipeline}
    \label{fig:enter-label}
\end{figure}

Osserva bene la tabella considerando la singola funzione di ogni istruzione. Al quarto ciclo di clock si vuole sottrarre il valore 1 al contenuto del registro \%EBX, ma questo non è stato ancora preparato da WriteBack, quindi sarà necessario aspettare un ciclo di clock per effettuare poi il decoding.\par\quad
Da questo puoi notare come un registro non sia pronto quando viene effettuata la WriteBack, bensì a quello successivo.\par\quad
Esistono inoltre delle strategie per la riduzione delle bolle; per le condizioni si allontanano le istruzioni che dipendono le une dalle altre, mentre per i cicli ci si affida ad un riconoscimento di pattern tramite le \textit{jump predictions}\footnote{La CPU osserva il primo risultato della condizione e implica che questo avvenga anche alla prossima richiesta. Si prepara di conseguenza per l'output che si aspetta.}.\par\quad
In questo caso, se il risultato del salto è predetto correttamente, si potrà effettuare il fetch della prima istruzione al nono ciclo di clock, ottenendo un CPI medio di $\frac{12-4}{6} = 1,35$CPI, che si avvicina molto al nostro obiettivo.\par\quad
Per chiarire, infine, la preparazione è del tutto innocua in quanto non va a modificare alcun registro.

\begin{figure}[b]
    \centering
    \includegraphics[width=0.7\linewidth]{Images/pipelineInstr.drawio.png}
    \caption{Istruzioni pipeline}
    \label{fig:enter-label}
\end{figure}